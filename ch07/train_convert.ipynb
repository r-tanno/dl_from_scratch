{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "opti='SDprop'\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer=opti, optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2290297588431036\n",
      "=== epoch:1, train acc:0.093, test acc:0.107 ===\n",
      "train loss:2.1056298015304926\n",
      "train loss:2.1395640901399204\n",
      "train loss:1.8406000855626874\n",
      "train loss:1.7640351958574667\n",
      "train loss:1.7794435852448138\n",
      "train loss:1.418485071562165\n",
      "train loss:1.1989756681600376\n",
      "train loss:0.8481160125757404\n",
      "train loss:0.9425596425993684\n",
      "train loss:1.3883940551000853\n",
      "train loss:1.0294065220155761\n",
      "train loss:0.7534112980885659\n",
      "train loss:0.6120914747102292\n",
      "train loss:0.6044372427675379\n",
      "train loss:0.5423140553721651\n",
      "train loss:0.5418230534759322\n",
      "train loss:0.5647609721259347\n",
      "train loss:0.6318216175712158\n",
      "train loss:0.442276865173721\n",
      "train loss:0.42019162543167965\n",
      "train loss:0.44992663300196073\n",
      "train loss:0.3754633746661149\n",
      "train loss:0.45343880460170255\n",
      "train loss:0.4171635875814487\n",
      "train loss:0.4096839511892744\n",
      "train loss:0.434144577597682\n",
      "train loss:0.30289861025418036\n",
      "train loss:0.3916440850198033\n",
      "train loss:0.4104157855564112\n",
      "train loss:0.2969309003151184\n",
      "train loss:0.28098345640547157\n",
      "train loss:0.29386896692297687\n",
      "train loss:0.27822991489563664\n",
      "train loss:0.3064192157626306\n",
      "train loss:0.27844577226959705\n",
      "train loss:0.4139993027098325\n",
      "train loss:0.36051978692552916\n",
      "train loss:0.25359578059069643\n",
      "train loss:0.23390667425939604\n",
      "train loss:0.2173014986691552\n",
      "train loss:0.264213459737907\n",
      "train loss:0.2802154683134007\n",
      "train loss:0.3944032363959238\n",
      "train loss:0.20320373198570255\n",
      "train loss:0.17059595774469255\n",
      "train loss:0.22717171251208174\n",
      "train loss:0.17142876573966895\n",
      "train loss:0.2584346065922615\n",
      "train loss:0.18943711525844387\n",
      "train loss:0.3190607289210413\n",
      "=== epoch:2, train acc:0.906, test acc:0.893 ===\n",
      "train loss:0.21069847359562816\n",
      "train loss:0.2954579996958456\n",
      "train loss:0.22052122333662294\n",
      "train loss:0.23738456917888193\n",
      "train loss:0.2887099063099824\n",
      "train loss:0.2109054132853659\n",
      "train loss:0.1838117716442391\n",
      "train loss:0.14137004460353955\n",
      "train loss:0.24915944204416696\n",
      "train loss:0.21675857804570797\n",
      "train loss:0.18702373511286485\n",
      "train loss:0.17326288100887247\n",
      "train loss:0.20881727901054428\n",
      "train loss:0.23033387413737752\n",
      "train loss:0.15245282983580458\n",
      "train loss:0.10572572357368483\n",
      "train loss:0.1439672946501341\n",
      "train loss:0.1412360143961517\n",
      "train loss:0.13436085646263918\n",
      "train loss:0.1713366786309162\n",
      "train loss:0.18207559717464675\n",
      "train loss:0.08483378177263987\n",
      "train loss:0.346250111616617\n",
      "train loss:0.12528271647334988\n",
      "train loss:0.12347032122739413\n",
      "train loss:0.1493865960356888\n",
      "train loss:0.2203669155790876\n",
      "train loss:0.12459905761633612\n",
      "train loss:0.2821555803453604\n",
      "train loss:0.13141854252333915\n",
      "train loss:0.13148357058379764\n",
      "train loss:0.1499919352137395\n",
      "train loss:0.15115934762229838\n",
      "train loss:0.13664921918548992\n",
      "train loss:0.122600871739258\n",
      "train loss:0.1465304402083742\n",
      "train loss:0.07811632869244083\n",
      "train loss:0.14363619449357867\n",
      "train loss:0.18100203455901723\n",
      "train loss:0.15598414710165742\n",
      "train loss:0.0707769955910891\n",
      "train loss:0.26383552464412313\n",
      "train loss:0.09908347958542812\n",
      "train loss:0.12163348558619848\n",
      "train loss:0.16375541552495743\n",
      "train loss:0.1414448748544199\n",
      "train loss:0.12966414801078363\n",
      "train loss:0.13471318166246282\n",
      "train loss:0.10263072027786563\n",
      "train loss:0.12064589972773215\n",
      "=== epoch:3, train acc:0.935, test acc:0.921 ===\n",
      "train loss:0.1399854075587593\n",
      "train loss:0.10553179386073148\n",
      "train loss:0.08864171779402243\n",
      "train loss:0.08536604827166126\n",
      "train loss:0.09047421180087536\n",
      "train loss:0.11189068105971547\n",
      "train loss:0.12925343285936594\n",
      "train loss:0.12454390275203493\n",
      "train loss:0.11639360552815621\n",
      "train loss:0.1184252863543426\n",
      "train loss:0.05807472231567774\n",
      "train loss:0.10751755728583719\n",
      "train loss:0.08964737715634684\n",
      "train loss:0.11992240792406723\n",
      "train loss:0.1784401363962817\n",
      "train loss:0.09433721931561974\n",
      "train loss:0.10595025608612778\n",
      "train loss:0.17088272701240537\n",
      "train loss:0.15735515455384358\n",
      "train loss:0.07740965614297086\n",
      "train loss:0.20792424985051028\n",
      "train loss:0.06683656594440875\n",
      "train loss:0.16731025097992444\n",
      "train loss:0.0923142629355445\n",
      "train loss:0.0627128381792218\n",
      "train loss:0.11124899649813623\n",
      "train loss:0.17357015750300786\n",
      "train loss:0.11558450286225488\n",
      "train loss:0.20754825632407\n",
      "train loss:0.10474510428195169\n",
      "train loss:0.17301129118691752\n",
      "train loss:0.08000076322997002\n",
      "train loss:0.14101474853873186\n",
      "train loss:0.0662386175493817\n",
      "train loss:0.1161540291289726\n",
      "train loss:0.10651952907194563\n",
      "train loss:0.17619112613188417\n",
      "train loss:0.10366026897978042\n",
      "train loss:0.06485247012025647\n",
      "train loss:0.04938195659607322\n",
      "train loss:0.15009924113256573\n",
      "train loss:0.06635723524487692\n",
      "train loss:0.08291913274932927\n",
      "train loss:0.1336266785939667\n",
      "train loss:0.05827175140338804\n",
      "train loss:0.07931433980529068\n",
      "train loss:0.06252264905626112\n",
      "train loss:0.11388106756995685\n",
      "train loss:0.11279175709396526\n",
      "train loss:0.12815144598598424\n",
      "=== epoch:4, train acc:0.953, test acc:0.931 ===\n",
      "train loss:0.1304969600697349\n",
      "train loss:0.053458659296161004\n",
      "train loss:0.16408702292880836\n",
      "train loss:0.09308885004992902\n",
      "train loss:0.08711358464820212\n",
      "train loss:0.16033511594845953\n",
      "train loss:0.11004613792669281\n",
      "train loss:0.06242077085114653\n",
      "train loss:0.06306857724326412\n",
      "train loss:0.06628024106591358\n",
      "train loss:0.07491235235308055\n",
      "train loss:0.08267583044419173\n",
      "train loss:0.05882411953406476\n",
      "train loss:0.09049979531330495\n",
      "train loss:0.053984075756291106\n",
      "train loss:0.03457764979559121\n",
      "train loss:0.06195883900172258\n",
      "train loss:0.0350208449040681\n",
      "train loss:0.12088285315999515\n",
      "train loss:0.04001991574710906\n",
      "train loss:0.07242319250363613\n",
      "train loss:0.08528480629256753\n",
      "train loss:0.06364886240192544\n",
      "train loss:0.04228699684495555\n",
      "train loss:0.050597881497018736\n",
      "train loss:0.071138921547878\n",
      "train loss:0.06580354319897869\n",
      "train loss:0.06037943686870295\n",
      "train loss:0.07716612411043205\n",
      "train loss:0.08705968087872838\n",
      "train loss:0.11900300489009064\n",
      "train loss:0.04549988886571239\n",
      "train loss:0.07590128713723439\n",
      "train loss:0.06270072795040013\n",
      "train loss:0.05983616240260061\n",
      "train loss:0.14511253556078663\n",
      "train loss:0.10234401731110024\n",
      "train loss:0.05906983052527447\n",
      "train loss:0.06380921551671413\n",
      "train loss:0.11709325485243481\n",
      "train loss:0.08947805114166878\n",
      "train loss:0.0724192233249061\n",
      "train loss:0.04732880285297061\n",
      "train loss:0.039825990619250684\n",
      "train loss:0.05345737801496365\n",
      "train loss:0.02885886577401125\n",
      "train loss:0.06113660717079242\n",
      "train loss:0.05320456768756476\n",
      "train loss:0.06443283357102744\n",
      "train loss:0.06518704105852102\n",
      "=== epoch:5, train acc:0.963, test acc:0.94 ===\n",
      "train loss:0.10531818413023211\n",
      "train loss:0.029423959263731484\n",
      "train loss:0.03104946738222293\n",
      "train loss:0.04891337407815963\n",
      "train loss:0.04102278508525003\n",
      "train loss:0.06050558694151245\n",
      "train loss:0.027919295311278063\n",
      "train loss:0.09855131077772246\n",
      "train loss:0.04304286290640953\n",
      "train loss:0.035066300838543285\n",
      "train loss:0.05421196660106856\n",
      "train loss:0.05093294521652934\n",
      "train loss:0.04705297413250486\n",
      "train loss:0.03686956398090034\n",
      "train loss:0.03703331920814746\n",
      "train loss:0.03840298553934013\n",
      "train loss:0.048371062378648993\n",
      "train loss:0.027277005460299965\n",
      "train loss:0.1016038827876379\n",
      "train loss:0.03622434267133391\n",
      "train loss:0.04162050409135966\n",
      "train loss:0.12328267280113302\n",
      "train loss:0.056691633050879944\n",
      "train loss:0.06037867038607273\n",
      "train loss:0.034809234122032524\n",
      "train loss:0.0805993057274731\n",
      "train loss:0.12341448757170925\n",
      "train loss:0.034527216517162965\n",
      "train loss:0.05107442360861989\n",
      "train loss:0.06322792189025118\n",
      "train loss:0.02021638057479596\n",
      "train loss:0.08659867182580908\n",
      "train loss:0.05279493195796721\n",
      "train loss:0.04088078294770958\n",
      "train loss:0.02973736511154108\n",
      "train loss:0.036051193458219145\n",
      "train loss:0.07375661197759445\n",
      "train loss:0.02909471270078634\n",
      "train loss:0.056353743693526165\n",
      "train loss:0.02677887844076573\n",
      "train loss:0.10338961184322777\n",
      "train loss:0.05468312186393754\n",
      "train loss:0.027386805551636164\n",
      "train loss:0.02785530210682089\n",
      "train loss:0.030685872121685148\n",
      "train loss:0.023803545480578104\n",
      "train loss:0.02954024734676782\n",
      "train loss:0.02091210176792528\n",
      "train loss:0.020774075300435606\n",
      "train loss:0.10056859817737085\n",
      "=== epoch:6, train acc:0.968, test acc:0.95 ===\n",
      "train loss:0.039093140482372314\n",
      "train loss:0.06424545072320594\n",
      "train loss:0.04305085296668214\n",
      "train loss:0.10010631456299623\n",
      "train loss:0.02550846495611539\n",
      "train loss:0.022017744566350365\n",
      "train loss:0.06223167496668228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0834037452905457\n",
      "train loss:0.028342653484536004\n",
      "train loss:0.029035559661452204\n",
      "train loss:0.03080181962659755\n",
      "train loss:0.04019084242362595\n",
      "train loss:0.023413308447201953\n",
      "train loss:0.040181472105691576\n",
      "train loss:0.03152111325893427\n",
      "train loss:0.034929835189877904\n",
      "train loss:0.023595812381442857\n",
      "train loss:0.06684416833244845\n",
      "train loss:0.02787449025704886\n",
      "train loss:0.027268398463418074\n",
      "train loss:0.05923361845301785\n",
      "train loss:0.040486332542380724\n",
      "train loss:0.03330984931054005\n",
      "train loss:0.07830927328270111\n",
      "train loss:0.069055987642517\n",
      "train loss:0.031036212824040916\n",
      "train loss:0.02538039020438545\n",
      "train loss:0.0750573035868191\n",
      "train loss:0.09504110389377253\n",
      "train loss:0.02484696609598609\n",
      "train loss:0.038711857574620735\n",
      "train loss:0.03496941034199108\n",
      "train loss:0.08343759375405266\n",
      "train loss:0.01899676415680783\n",
      "train loss:0.03209405343698121\n",
      "train loss:0.04719158446071295\n",
      "train loss:0.0810022379249641\n",
      "train loss:0.02272687215079688\n",
      "train loss:0.024002883638118106\n",
      "train loss:0.055288910607443745\n",
      "train loss:0.024053889384767806\n",
      "train loss:0.03703859128060196\n",
      "train loss:0.03770006937138539\n",
      "train loss:0.02604621780300523\n",
      "train loss:0.06091438997394943\n",
      "train loss:0.026231604924983838\n",
      "train loss:0.03134750887571367\n",
      "train loss:0.0213134543944571\n",
      "train loss:0.049148276134029875\n",
      "train loss:0.026475129831829584\n",
      "=== epoch:7, train acc:0.977, test acc:0.947 ===\n",
      "train loss:0.022281961454209475\n",
      "train loss:0.041576553690293616\n",
      "train loss:0.017271204181780644\n",
      "train loss:0.02039274308664091\n",
      "train loss:0.055225354530325454\n",
      "train loss:0.05116623017695161\n",
      "train loss:0.023716229608749955\n",
      "train loss:0.036167200879984054\n",
      "train loss:0.01904282440264953\n",
      "train loss:0.020769766141757077\n",
      "train loss:0.01994598663559778\n",
      "train loss:0.017162171789245607\n",
      "train loss:0.04377920117940641\n",
      "train loss:0.03416117982493806\n",
      "train loss:0.02017322458953651\n",
      "train loss:0.02042825197101567\n",
      "train loss:0.0239864876138954\n",
      "train loss:0.01848851329728879\n",
      "train loss:0.03194229014125418\n",
      "train loss:0.022291046771523416\n",
      "train loss:0.03697872395104238\n",
      "train loss:0.03495742141154989\n",
      "train loss:0.012480686299254645\n",
      "train loss:0.050321878201431317\n",
      "train loss:0.040061327616363746\n",
      "train loss:0.018467016611896477\n",
      "train loss:0.01937650236478102\n",
      "train loss:0.013474341856206842\n",
      "train loss:0.04735398979950152\n",
      "train loss:0.019506055868945944\n",
      "train loss:0.014853000674488437\n",
      "train loss:0.022493091468060177\n",
      "train loss:0.0469998115737374\n",
      "train loss:0.025824978535629373\n",
      "train loss:0.02705607715851712\n",
      "train loss:0.02576057178344897\n",
      "train loss:0.04088853422346753\n",
      "train loss:0.04768912254023658\n",
      "train loss:0.019843793503995243\n",
      "train loss:0.060652914707344664\n",
      "train loss:0.023347200798321432\n",
      "train loss:0.03152211473123976\n",
      "train loss:0.04959803073535716\n",
      "train loss:0.03867912405338829\n",
      "train loss:0.021284706458357658\n",
      "train loss:0.01619025380165276\n",
      "train loss:0.050519938752920705\n",
      "train loss:0.042970586413317226\n",
      "train loss:0.016576854355825954\n",
      "train loss:0.058417693090381785\n",
      "=== epoch:8, train acc:0.977, test acc:0.956 ===\n",
      "train loss:0.009602808701647312\n",
      "train loss:0.014903536917161706\n",
      "train loss:0.023421016708020263\n",
      "train loss:0.032755003421455896\n",
      "train loss:0.05106327307756133\n",
      "train loss:0.038498797605595714\n",
      "train loss:0.026422809602861398\n",
      "train loss:0.01205782153492006\n",
      "train loss:0.027178154460783862\n",
      "train loss:0.017717229481828804\n",
      "train loss:0.028075565965367474\n",
      "train loss:0.030733687237615145\n",
      "train loss:0.0294653594105342\n",
      "train loss:0.018948479689829708\n",
      "train loss:0.02783425574584994\n",
      "train loss:0.031053608813176887\n",
      "train loss:0.042414123603758756\n",
      "train loss:0.012091723884963412\n",
      "train loss:0.01231295412964526\n",
      "train loss:0.05334288913318658\n",
      "train loss:0.018798432603073196\n",
      "train loss:0.04727516966312306\n",
      "train loss:0.012783049773196838\n",
      "train loss:0.04850825735981023\n",
      "train loss:0.09119857783765052\n",
      "train loss:0.04291025881952797\n",
      "train loss:0.03241016776973042\n",
      "train loss:0.030745372933844037\n",
      "train loss:0.029043958889014645\n",
      "train loss:0.033584804481875716\n",
      "train loss:0.028920978977721785\n",
      "train loss:0.011356044677140662\n",
      "train loss:0.02735692262760423\n",
      "train loss:0.01788355947780828\n",
      "train loss:0.01361136192405995\n",
      "train loss:0.01820665951090381\n",
      "train loss:0.011946263370436224\n",
      "train loss:0.043043653726420335\n",
      "train loss:0.008625789049453074\n",
      "train loss:0.015144917422576638\n",
      "train loss:0.0474054923531497\n",
      "train loss:0.014895608906176243\n",
      "train loss:0.026204966108627527\n",
      "train loss:0.03872457941233442\n",
      "train loss:0.026849613361185017\n",
      "train loss:0.010317702900067656\n",
      "train loss:0.020534302210649252\n",
      "train loss:0.025037365949478474\n",
      "train loss:0.016462874046433085\n",
      "train loss:0.017445126649677546\n",
      "=== epoch:9, train acc:0.988, test acc:0.965 ===\n",
      "train loss:0.025137675877459832\n",
      "train loss:0.015488148091895295\n",
      "train loss:0.02972933374587251\n",
      "train loss:0.035341065384006186\n",
      "train loss:0.013583404502703551\n",
      "train loss:0.0530110263774393\n",
      "train loss:0.023339195635177307\n",
      "train loss:0.012498436553709523\n",
      "train loss:0.02324583996219478\n",
      "train loss:0.013604618815194874\n",
      "train loss:0.01693430394352538\n",
      "train loss:0.06518693153582868\n",
      "train loss:0.006661540823709384\n",
      "train loss:0.025657930973013023\n",
      "train loss:0.011607194377681979\n",
      "train loss:0.046098809886213434\n",
      "train loss:0.036584076876089014\n",
      "train loss:0.0128055105051036\n",
      "train loss:0.017155822462760345\n",
      "train loss:0.019280275171421106\n",
      "train loss:0.01171123843417444\n",
      "train loss:0.015726447632228475\n",
      "train loss:0.007511847198722133\n",
      "train loss:0.01828403670589724\n",
      "train loss:0.00940380195484601\n",
      "train loss:0.02737910842345125\n",
      "train loss:0.03025625737363729\n",
      "train loss:0.01025482875588947\n",
      "train loss:0.014361337518403185\n",
      "train loss:0.016428197688122415\n",
      "train loss:0.026407744169381436\n",
      "train loss:0.0318481643158418\n",
      "train loss:0.011557845470096518\n",
      "train loss:0.009467278083601136\n",
      "train loss:0.015517641940717452\n",
      "train loss:0.017124070140824264\n",
      "train loss:0.034175950482365186\n",
      "train loss:0.024842937828604653\n",
      "train loss:0.04648395539631442\n",
      "train loss:0.029853918390578535\n",
      "train loss:0.01074401604155043\n",
      "train loss:0.03204911546002456\n",
      "train loss:0.05288815908284849\n",
      "train loss:0.018829419843512104\n",
      "train loss:0.018710454209834977\n",
      "train loss:0.011657718080986958\n",
      "train loss:0.019983383764961952\n",
      "train loss:0.023090111989140266\n",
      "train loss:0.018238834658673757\n",
      "train loss:0.03100052369437891\n",
      "=== epoch:10, train acc:0.978, test acc:0.957 ===\n",
      "train loss:0.009443640486761853\n",
      "train loss:0.0066176443168739826\n",
      "train loss:0.01523373289844808\n",
      "train loss:0.008215972261132591\n",
      "train loss:0.020084956384751815\n",
      "train loss:0.015213883419062046\n",
      "train loss:0.01251225281917676\n",
      "train loss:0.012932717826370827\n",
      "train loss:0.009672692531904371\n",
      "train loss:0.014714473669061336\n",
      "train loss:0.00964143109686495\n",
      "train loss:0.011339353035474942\n",
      "train loss:0.016302361259288908\n",
      "train loss:0.013230246821117047\n",
      "train loss:0.02302690924376087\n",
      "train loss:0.016521001525108783\n",
      "train loss:0.006948490612929757\n",
      "train loss:0.006772944794396872\n",
      "train loss:0.00997641386378535\n",
      "train loss:0.011738456685949156\n",
      "train loss:0.014936961728383264\n",
      "train loss:0.02078884747136502\n",
      "train loss:0.012100667916677727\n",
      "train loss:0.036150962631310145\n",
      "train loss:0.0265387859084157\n",
      "train loss:0.019118269636243534\n",
      "train loss:0.01651243559080873\n",
      "train loss:0.010788771235543728\n",
      "train loss:0.012627656111246457\n",
      "train loss:0.012304352179184965\n",
      "train loss:0.008610290459425214\n",
      "train loss:0.027834352013004042\n",
      "train loss:0.03864156670384929\n",
      "train loss:0.038082777489260616\n",
      "train loss:0.015133180157192833\n",
      "train loss:0.02110577886814064\n",
      "train loss:0.021509208949185052\n",
      "train loss:0.01836344333925455\n",
      "train loss:0.007756078722599053\n",
      "train loss:0.012412494169758198\n",
      "train loss:0.012288086667680206\n",
      "train loss:0.00954795957633131\n",
      "train loss:0.013438362444366475\n",
      "train loss:0.0042897306602579805\n",
      "train loss:0.008786868423981074\n",
      "train loss:0.012190665575527589\n",
      "train loss:0.007319237028688904\n",
      "train loss:0.05347992999996214\n",
      "train loss:0.012915857041163778\n",
      "train loss:0.020606379690474963\n",
      "=== epoch:11, train acc:0.989, test acc:0.965 ===\n",
      "train loss:0.00822888152866392\n",
      "train loss:0.025686369706244067\n",
      "train loss:0.007717325822798798\n",
      "train loss:0.02657879781429847\n",
      "train loss:0.01043297545364507\n",
      "train loss:0.008906176616153635\n",
      "train loss:0.018081137839923687\n",
      "train loss:0.00710795988085139\n",
      "train loss:0.013811420175107635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011624856065469515\n",
      "train loss:0.011227099106117132\n",
      "train loss:0.022061329946269446\n",
      "train loss:0.02699369638009146\n",
      "train loss:0.011505357339890547\n",
      "train loss:0.013406257340273715\n",
      "train loss:0.004520228007241924\n",
      "train loss:0.01318387250360684\n",
      "train loss:0.026036039667462707\n",
      "train loss:0.009286831265398414\n",
      "train loss:0.012078016309422507\n",
      "train loss:0.005538186700660811\n",
      "train loss:0.0059827317553026605\n",
      "train loss:0.00745797443125174\n",
      "train loss:0.008477854589446226\n",
      "train loss:0.012097396818739933\n",
      "train loss:0.02140765510242422\n",
      "train loss:0.014709441746627732\n",
      "train loss:0.015153344346336348\n",
      "train loss:0.00915097151974832\n",
      "train loss:0.006816172769892876\n",
      "train loss:0.020233035806286662\n",
      "train loss:0.008409132256703162\n",
      "train loss:0.06316681846323624\n",
      "train loss:0.018307084085363308\n",
      "train loss:0.007497722475429598\n",
      "train loss:0.011696180325805413\n",
      "train loss:0.00878903368317993\n",
      "train loss:0.004661281316512184\n",
      "train loss:0.004719099128459996\n",
      "train loss:0.009440769264679887\n",
      "train loss:0.004293273076842385\n",
      "train loss:0.010041213147461887\n",
      "train loss:0.007738067204675776\n",
      "train loss:0.007618021296326755\n",
      "train loss:0.03617100073289845\n",
      "train loss:0.0076688672205614495\n",
      "train loss:0.0031778696905277715\n",
      "train loss:0.008848813351330097\n",
      "train loss:0.014451774526934304\n",
      "train loss:0.011966901161481637\n",
      "=== epoch:12, train acc:0.991, test acc:0.964 ===\n",
      "train loss:0.006671534798185589\n",
      "train loss:0.015586463957981713\n",
      "train loss:0.007880731881599821\n",
      "train loss:0.005009780766089607\n",
      "train loss:0.0078873710089319\n",
      "train loss:0.009791494443231193\n",
      "train loss:0.011313992510008995\n",
      "train loss:0.009108062396574567\n",
      "train loss:0.00841740282964228\n",
      "train loss:0.006267356498953974\n",
      "train loss:0.016617723437947114\n",
      "train loss:0.00714964327059166\n",
      "train loss:0.013855050734857257\n",
      "train loss:0.009589098386380304\n",
      "train loss:0.005124676468528365\n",
      "train loss:0.005035179775320425\n",
      "train loss:0.010752862425225084\n",
      "train loss:0.010953123901583761\n",
      "train loss:0.006319651555526693\n",
      "train loss:0.026657943931790037\n",
      "train loss:0.004939953919917759\n",
      "train loss:0.010070661653854002\n",
      "train loss:0.010641800360379074\n",
      "train loss:0.049444120960040944\n",
      "train loss:0.004577228427333001\n",
      "train loss:0.007086876434564627\n",
      "train loss:0.009407068832750215\n",
      "train loss:0.017071394616789276\n",
      "train loss:0.0230061934083704\n",
      "train loss:0.042831438269503454\n",
      "train loss:0.07183906443899377\n",
      "train loss:0.010507807487360389\n",
      "train loss:0.055979609420866334\n",
      "train loss:0.0063929900104656556\n",
      "train loss:0.009682103776357455\n",
      "train loss:0.0073654093800357735\n",
      "train loss:0.005782968597494632\n",
      "train loss:0.006887945041618477\n",
      "train loss:0.006721819168428848\n",
      "train loss:0.01766429049164592\n",
      "train loss:0.02066084402287525\n",
      "train loss:0.00946550945502042\n",
      "train loss:0.007890936193948695\n",
      "train loss:0.004661539640845572\n",
      "train loss:0.0073827329835548326\n",
      "train loss:0.010544215021931137\n",
      "train loss:0.00992677960928422\n",
      "train loss:0.012557425177709289\n",
      "train loss:0.004150236531490995\n",
      "train loss:0.02061360272254755\n",
      "=== epoch:13, train acc:0.995, test acc:0.968 ===\n",
      "train loss:0.005523012869917037\n",
      "train loss:0.005014455013889748\n",
      "train loss:0.007127600565893575\n",
      "train loss:0.004411259915246254\n",
      "train loss:0.007082240056879042\n",
      "train loss:0.006544311909861369\n",
      "train loss:0.010331396738196406\n",
      "train loss:0.006030151410392584\n",
      "train loss:0.008237936197876793\n",
      "train loss:0.007755545889137341\n",
      "train loss:0.010955102278058041\n",
      "train loss:0.004083653307521896\n",
      "train loss:0.008942743971986654\n",
      "train loss:0.015119971818493639\n",
      "train loss:0.00475658620540996\n",
      "train loss:0.0039595982174096475\n",
      "train loss:0.005928652605342964\n",
      "train loss:0.006346734741496759\n",
      "train loss:0.008458421469186574\n",
      "train loss:0.00532585993907937\n",
      "train loss:0.004927297052181234\n",
      "train loss:0.00569129422796943\n",
      "train loss:0.004334452941209337\n",
      "train loss:0.004992196920715279\n",
      "train loss:0.004855878956648236\n",
      "train loss:0.006242476764873719\n",
      "train loss:0.006592664576976342\n",
      "train loss:0.005076960674062266\n",
      "train loss:0.0033417953401396485\n",
      "train loss:0.006870939765696472\n",
      "train loss:0.007350618891039705\n",
      "train loss:0.00703392860191412\n",
      "train loss:0.005148965264458569\n",
      "train loss:0.015675724899870312\n",
      "train loss:0.008223424542930778\n",
      "train loss:0.0058315160764181055\n",
      "train loss:0.005093818307466682\n",
      "train loss:0.005349091077836003\n",
      "train loss:0.003019970174546487\n",
      "train loss:0.009289961426059638\n",
      "train loss:0.007070165030550737\n",
      "train loss:0.01520519564282164\n",
      "train loss:0.0042748971693058165\n",
      "train loss:0.005628243491988306\n",
      "train loss:0.01768478398828545\n",
      "train loss:0.005223245144062536\n",
      "train loss:0.0066272510750055545\n",
      "train loss:0.01392672251151654\n",
      "train loss:0.007650375103189722\n",
      "train loss:0.0065992348822254835\n",
      "=== epoch:14, train acc:0.993, test acc:0.969 ===\n",
      "train loss:0.010859908057957971\n",
      "train loss:0.006288248202228845\n",
      "train loss:0.008703147874125544\n",
      "train loss:0.007943489415879405\n",
      "train loss:0.005484051360543902\n",
      "train loss:0.011899002370409832\n",
      "train loss:0.003169842206210083\n",
      "train loss:0.011267140747863846\n",
      "train loss:0.004464917601011048\n",
      "train loss:0.009678012261830637\n",
      "train loss:0.0072403000316196885\n",
      "train loss:0.011134517787932348\n",
      "train loss:0.009465149545390529\n",
      "train loss:0.005593278822915652\n",
      "train loss:0.00291494102506864\n",
      "train loss:0.005951661160437656\n",
      "train loss:0.004941880456282811\n",
      "train loss:0.004202074960570688\n",
      "train loss:0.015004139484278154\n",
      "train loss:0.006125612224727743\n",
      "train loss:0.004819486150380497\n",
      "train loss:0.00910704624935017\n",
      "train loss:0.004879239907733717\n",
      "train loss:0.005729324573812249\n",
      "train loss:0.010237075859886799\n",
      "train loss:0.007134045229581118\n",
      "train loss:0.004702256677289005\n",
      "train loss:0.006585637386154051\n",
      "train loss:0.00847615429737374\n",
      "train loss:0.004789934868599078\n",
      "train loss:0.00661823603515064\n",
      "train loss:0.004684765222660919\n",
      "train loss:0.005587689370329172\n",
      "train loss:0.003955777461142289\n",
      "train loss:0.002149449695110428\n",
      "train loss:0.003733349027567173\n",
      "train loss:0.008033329336960262\n",
      "train loss:0.005185381017096352\n",
      "train loss:0.003451951322409187\n",
      "train loss:0.003945850454737304\n",
      "train loss:0.003905195223659225\n",
      "train loss:0.00720097624730732\n",
      "train loss:0.002811557271340335\n",
      "train loss:0.004047446463296061\n",
      "train loss:0.003420258025698417\n",
      "train loss:0.003919024080103165\n",
      "train loss:0.0035209614239673152\n",
      "train loss:0.005094128197311806\n",
      "train loss:0.013012911820590356\n",
      "train loss:0.004674786693645901\n",
      "=== epoch:15, train acc:0.996, test acc:0.962 ===\n",
      "train loss:0.003730964796723216\n",
      "train loss:0.00398069355634577\n",
      "train loss:0.049715237771963745\n",
      "train loss:0.003932274280836864\n",
      "train loss:0.003391554692713865\n",
      "train loss:0.005852517040202729\n",
      "train loss:0.008350048263913263\n",
      "train loss:0.004483649972444795\n",
      "train loss:0.008114351524488238\n",
      "train loss:0.0025543004505496248\n",
      "train loss:0.0030597856597873677\n",
      "train loss:0.00555140647427049\n",
      "train loss:0.01265205575368288\n",
      "train loss:0.002762291985968302\n",
      "train loss:0.0025797541820682924\n",
      "train loss:0.0032633205165149676\n",
      "train loss:0.0019930127438669842\n",
      "train loss:0.011274445823347079\n",
      "train loss:0.01489600422723727\n",
      "train loss:0.006273873296310314\n",
      "train loss:0.004218428332300763\n",
      "train loss:0.0026141229202164985\n",
      "train loss:0.004499884035059862\n",
      "train loss:0.011898005255834914\n",
      "train loss:0.015641739069330782\n",
      "train loss:0.003370586995271218\n",
      "train loss:0.0072255422417347144\n",
      "train loss:0.008379679463362662\n",
      "train loss:0.016505649342609244\n",
      "train loss:0.005142570237366647\n",
      "train loss:0.005186249050508879\n",
      "train loss:0.0046883596978619406\n",
      "train loss:0.0022158878203235822\n",
      "train loss:0.007212979750240944\n",
      "train loss:0.004417203629438298\n",
      "train loss:0.004872889508473433\n",
      "train loss:0.006746103090121149\n",
      "train loss:0.002777603924684474\n",
      "train loss:0.009113142917623036\n",
      "train loss:0.011449354868099783\n",
      "train loss:0.00619353829904401\n",
      "train loss:0.004300150715213901\n",
      "train loss:0.00558162486572098\n",
      "train loss:0.0026496088617260355\n",
      "train loss:0.004306553569121029\n",
      "train loss:0.0026946500252977633\n",
      "train loss:0.002381718536893709\n",
      "train loss:0.0073747919235879235\n",
      "train loss:0.0023583518185022164\n",
      "train loss:0.0016074183538737294\n",
      "=== epoch:16, train acc:0.996, test acc:0.966 ===\n",
      "train loss:0.003163793772759838\n",
      "train loss:0.004359240717276825\n",
      "train loss:0.002136888888303587\n",
      "train loss:0.0028343902176409534\n",
      "train loss:0.004249344801702701\n",
      "train loss:0.020198083178155985\n",
      "train loss:0.006827248959042767\n",
      "train loss:0.023603216100505895\n",
      "train loss:0.08670429854892038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.025445921459028856\n",
      "train loss:0.006532060768972305\n",
      "train loss:0.006082118751593055\n",
      "train loss:0.0030999556277350455\n",
      "train loss:0.004537842137540022\n",
      "train loss:0.0016737116490004571\n",
      "train loss:0.005566201162659715\n",
      "train loss:0.001291628925504627\n",
      "train loss:0.0036444574166606476\n",
      "train loss:0.01248904720135149\n",
      "train loss:0.0030131654829781847\n",
      "train loss:0.0032287237270827536\n",
      "train loss:0.004497379946698092\n",
      "train loss:0.0036443862172334373\n",
      "train loss:0.004219244271179937\n",
      "train loss:0.006989657646880667\n",
      "train loss:0.003562589027155573\n",
      "train loss:0.0031256535227001166\n",
      "train loss:0.0024325100970457873\n",
      "train loss:0.00907263036406192\n",
      "train loss:0.0030013476426737685\n",
      "train loss:0.007302139178096887\n",
      "train loss:0.001807916826067743\n",
      "train loss:0.002821761653555346\n",
      "train loss:0.0034251086885662353\n",
      "train loss:0.0037647780182064844\n",
      "train loss:0.0027140930654828742\n",
      "train loss:0.001756392733648597\n",
      "train loss:0.0009505158652937727\n",
      "train loss:0.0035775169823001125\n",
      "train loss:0.0030287649551102957\n",
      "train loss:0.002766523913679122\n",
      "train loss:0.00285629430880585\n",
      "train loss:0.010623695969657138\n",
      "train loss:0.002163193358280584\n",
      "train loss:0.0024612258064597974\n",
      "train loss:0.002412084724759913\n",
      "train loss:0.002542822062844287\n",
      "train loss:0.0026450053322350964\n",
      "train loss:0.0028470643424776793\n",
      "train loss:0.003420385021267678\n",
      "=== epoch:17, train acc:0.997, test acc:0.968 ===\n",
      "train loss:0.005661352429385097\n",
      "train loss:0.0041164849321497195\n",
      "train loss:0.003934369088791659\n",
      "train loss:0.004919031418990502\n",
      "train loss:0.003378323552926453\n",
      "train loss:0.003270308489343294\n",
      "train loss:0.0017608427797445908\n",
      "train loss:0.004506202550437452\n",
      "train loss:0.012868237967349231\n",
      "train loss:0.0017832251675057162\n",
      "train loss:0.003413063566938896\n",
      "train loss:0.001316639928373177\n",
      "train loss:0.002386130323291176\n",
      "train loss:0.00405024027569413\n",
      "train loss:0.002248340736407247\n",
      "train loss:0.00697638655285415\n",
      "train loss:0.004313534588014792\n",
      "train loss:0.0017529730126802949\n",
      "train loss:0.00226293466672307\n",
      "train loss:0.0012915271811126654\n",
      "train loss:0.0022674970963106537\n",
      "train loss:0.011340474920791356\n",
      "train loss:0.0023228871708094274\n",
      "train loss:0.0024926642840345536\n",
      "train loss:0.012553118651288555\n",
      "train loss:0.008867421127454587\n",
      "train loss:0.002287074549399848\n",
      "train loss:0.0021422291854684876\n",
      "train loss:0.0024560944977712936\n",
      "train loss:0.0018708617597051225\n",
      "train loss:0.0015366616729017297\n",
      "train loss:0.004650216155881426\n",
      "train loss:0.00477013877827128\n",
      "train loss:0.0018464214368950948\n",
      "train loss:0.003250933136408301\n",
      "train loss:0.0026591421825609574\n",
      "train loss:0.0009823437502467852\n",
      "train loss:0.0023110723887285693\n",
      "train loss:0.002843697382152379\n",
      "train loss:0.0024286412364873697\n",
      "train loss:0.0016836166786345572\n",
      "train loss:0.0021835918600240016\n",
      "train loss:0.0016907553967043284\n",
      "train loss:0.00524008903382075\n",
      "train loss:0.0017470892331152496\n",
      "train loss:0.001981152449869312\n",
      "train loss:0.0021347790263700943\n",
      "train loss:0.001480512099311328\n",
      "train loss:0.0016435968618299238\n",
      "train loss:0.0020928201767466477\n",
      "=== epoch:18, train acc:0.999, test acc:0.969 ===\n",
      "train loss:0.003465938021952551\n",
      "train loss:0.0021996428576309913\n",
      "train loss:0.0009950576023651683\n",
      "train loss:0.002999485191321511\n",
      "train loss:0.007003861230486812\n",
      "train loss:0.0008196164107598077\n",
      "train loss:0.0035252155042863604\n",
      "train loss:0.0031327976730870866\n",
      "train loss:0.0031292198132664463\n",
      "train loss:0.002283401395709597\n",
      "train loss:0.0016839122716475732\n",
      "train loss:0.0018146273832397885\n",
      "train loss:0.0027786939615997487\n",
      "train loss:0.0017802784706666087\n",
      "train loss:0.0018595809543315548\n",
      "train loss:0.0018003262279141486\n",
      "train loss:0.0019063506237806391\n",
      "train loss:0.002280886783120283\n",
      "train loss:0.0016825626618492931\n",
      "train loss:0.0015616531205969312\n",
      "train loss:0.002241351303259016\n",
      "train loss:0.0028264722293996412\n",
      "train loss:0.004270177545488276\n",
      "train loss:0.002593856452378821\n",
      "train loss:0.0016347728351140361\n",
      "train loss:0.0023064363195521905\n",
      "train loss:0.001757895139155867\n",
      "train loss:0.0012306411905203968\n",
      "train loss:0.0016224590923838238\n",
      "train loss:0.0011931192313510911\n",
      "train loss:0.0009136895012251663\n",
      "train loss:0.0010127021277250752\n",
      "train loss:0.002605921222743336\n",
      "train loss:0.002498036392482862\n",
      "train loss:0.0013113889417694438\n",
      "train loss:0.0011509445262201346\n",
      "train loss:0.0021809180004373195\n",
      "train loss:0.0012358286091286078\n",
      "train loss:0.0019396759595860678\n",
      "train loss:0.0006795689560071996\n",
      "train loss:0.001542598880057225\n",
      "train loss:0.0012845433801879653\n",
      "train loss:0.0021221585168375713\n",
      "train loss:0.0009400906235299704\n",
      "train loss:0.00265727048801801\n",
      "train loss:0.0017446034256527077\n",
      "train loss:0.0011490491526613548\n",
      "train loss:0.002697693702118034\n",
      "train loss:0.0013344904512869302\n",
      "train loss:0.0008556766836374974\n",
      "=== epoch:19, train acc:1.0, test acc:0.968 ===\n",
      "train loss:0.00188351096575061\n",
      "train loss:0.0013162339569830579\n",
      "train loss:0.0014772777527477423\n",
      "train loss:0.0017102474387820051\n",
      "train loss:0.0011347673593992925\n",
      "train loss:0.002312072598377099\n",
      "train loss:0.0016906354977951133\n",
      "train loss:0.0014715609477945948\n",
      "train loss:0.0011457820170474218\n",
      "train loss:0.0019588930584260042\n",
      "train loss:0.0013520900221848278\n",
      "train loss:0.001412792957479703\n",
      "train loss:0.0020181847445762857\n",
      "train loss:0.001430698872256323\n",
      "train loss:0.0030055304002929665\n",
      "train loss:0.00134990558266209\n",
      "train loss:0.0016917338264079654\n",
      "train loss:0.0006988448247158885\n",
      "train loss:0.0016427004006003476\n",
      "train loss:0.0018761585571582357\n",
      "train loss:0.0019244937608104357\n",
      "train loss:0.0022743102125503518\n",
      "train loss:0.0024598497825391273\n",
      "train loss:0.14168984994381464\n",
      "train loss:1.1476483617039497\n",
      "train loss:0.12357003808037396\n",
      "train loss:0.0056139774765755004\n",
      "train loss:0.003557904985944396\n",
      "train loss:0.006037318877332346\n",
      "train loss:0.0033760448598186945\n",
      "train loss:0.0027634443518793957\n",
      "train loss:0.003323633398763929\n",
      "train loss:0.0034681526007984925\n",
      "train loss:0.005067501583833094\n",
      "train loss:0.0015194244549572797\n",
      "train loss:0.00331925624298634\n",
      "train loss:0.004998384591932364\n",
      "train loss:0.002295275880663798\n",
      "train loss:0.003747973550593951\n",
      "train loss:0.0023264257427181327\n",
      "train loss:0.004421749339716166\n",
      "train loss:0.001614771424499655\n",
      "train loss:0.0015098852201420074\n",
      "train loss:0.003658497606292168\n",
      "train loss:0.0020332555424341617\n",
      "train loss:0.003563779662618915\n",
      "train loss:0.002578070255860369\n",
      "train loss:0.0016158269935307524\n",
      "train loss:0.005829576388385647\n",
      "train loss:0.003668555591154224\n",
      "=== epoch:20, train acc:0.999, test acc:0.971 ===\n",
      "train loss:0.002192519061081361\n",
      "train loss:0.0027680922996086727\n",
      "train loss:0.0028178586766362122\n",
      "train loss:0.011742770716132875\n",
      "train loss:0.004256952626946227\n",
      "train loss:0.006789093125767304\n",
      "train loss:0.0015251158828120126\n",
      "train loss:0.003394450708289965\n",
      "train loss:0.0023019853278696788\n",
      "train loss:0.002548046529561714\n",
      "train loss:0.0011803253326326969\n",
      "train loss:0.001221988251247541\n",
      "train loss:0.003079756527926075\n",
      "train loss:0.0030876893535815263\n",
      "train loss:0.0019999608394873068\n",
      "train loss:0.0022310283934742054\n",
      "train loss:0.0036040281249973623\n",
      "train loss:0.004268730282211568\n",
      "train loss:0.0013061155778160182\n",
      "train loss:0.0027262549362661935\n",
      "train loss:0.002894435794194156\n",
      "train loss:0.0014401798623922349\n",
      "train loss:0.004839826336828188\n",
      "train loss:0.0024007759521223254\n",
      "train loss:0.004209959982021421\n",
      "train loss:0.0033264998725194266\n",
      "train loss:0.002322686371905666\n",
      "train loss:0.0020909259886413233\n",
      "train loss:0.0033765142487067567\n",
      "train loss:0.00234883327788942\n",
      "train loss:0.0021801923470912347\n",
      "train loss:0.0010125708502360187\n",
      "train loss:0.002566456050620164\n",
      "train loss:0.001718788743537311\n",
      "train loss:0.0022862049201558578\n",
      "train loss:0.0010164820738640308\n",
      "train loss:0.004509712739671668\n",
      "train loss:0.0025157925687739535\n",
      "train loss:0.002297058424358292\n",
      "train loss:0.0018137312792121387\n",
      "train loss:0.0013115240537797032\n",
      "train loss:0.0012957383560040097\n",
      "train loss:0.001762949067674362\n",
      "train loss:0.002471481950022407\n",
      "train loss:0.0040649663915984305\n",
      "train loss:0.0012909752531234345\n",
      "train loss:0.0014889589482893306\n",
      "train loss:0.002480132435807367\n",
      "train loss:0.0016218418228697714\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.971\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "# パラメータの保存\n",
    "network.save_params(opti + \".params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti='RMSprop'\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer=opti, optimizer_param={'lr': 0.01},\n",
    "                  evaluate_sample_num_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:12.94170995640842\n",
      "=== epoch:1, train acc:0.139, test acc:0.127 ===\n",
      "train loss:12.11196951278118\n",
      "train loss:4.3254219253525745\n",
      "train loss:1.470850997174835\n",
      "train loss:1.1794172984815785\n",
      "train loss:1.771761872084061\n",
      "train loss:1.8173429578061797\n",
      "train loss:0.6442922570543328\n",
      "train loss:0.6425241823905687\n",
      "train loss:0.29477522916376186\n",
      "train loss:0.31001435936838156\n",
      "train loss:0.15941572074962757\n",
      "train loss:0.3279935160949838\n",
      "train loss:0.17647696120690212\n",
      "train loss:0.2106446820107845\n",
      "train loss:0.19499236329746206\n",
      "train loss:0.16446051119166544\n",
      "train loss:0.17228939633804644\n",
      "train loss:0.15294691797682394\n",
      "train loss:0.11785754135605567\n",
      "train loss:0.15118916103240254\n",
      "train loss:0.11063534355323645\n",
      "train loss:0.10436520365906743\n",
      "train loss:0.11606101519998686\n",
      "train loss:0.06701660362495447\n",
      "train loss:0.0989370770349561\n",
      "train loss:0.12136796598461867\n",
      "train loss:0.06815000331761588\n",
      "train loss:0.0834217555085401\n",
      "train loss:0.1173924158797414\n",
      "train loss:0.06572058569373626\n",
      "train loss:0.06416331517694115\n",
      "train loss:0.06306004986957241\n",
      "train loss:0.09507723980708241\n",
      "train loss:0.13480623964989927\n",
      "train loss:0.07281196465622437\n",
      "train loss:0.06014582284572142\n",
      "train loss:0.06907697657506438\n",
      "train loss:0.0400202794645102\n",
      "train loss:0.044192713997309896\n",
      "train loss:0.049252093722327785\n",
      "train loss:0.11924621844799066\n",
      "train loss:0.13284529828414354\n",
      "train loss:0.10008822167129038\n",
      "train loss:0.06702673446583543\n",
      "train loss:0.060177926829189446\n",
      "train loss:0.041517358763622905\n",
      "train loss:0.09405956774380853\n",
      "train loss:0.09539695465361123\n",
      "train loss:0.07214343229689223\n",
      "train loss:0.05729626102817077\n",
      "=== epoch:2, train acc:0.958, test acc:0.924 ===\n",
      "train loss:0.08061545063946333\n",
      "train loss:0.035495961841824075\n",
      "train loss:0.03921336419812199\n",
      "train loss:0.041344287343045086\n",
      "train loss:0.027591256723160318\n",
      "train loss:0.06876640989283907\n",
      "train loss:0.05422967434297243\n",
      "train loss:0.06795138487976944\n",
      "train loss:0.10426963684252563\n",
      "train loss:0.09327452826650509\n",
      "train loss:0.03590268093822476\n",
      "train loss:0.0433352275691958\n",
      "train loss:0.05375362349194252\n",
      "train loss:0.05921105175929473\n",
      "train loss:0.06262645750555244\n",
      "train loss:0.04726220529242942\n",
      "train loss:0.04616449283048029\n",
      "train loss:0.07097346172978092\n",
      "train loss:0.018112213958124488\n",
      "train loss:0.024840935843294235\n",
      "train loss:0.04598513592971826\n",
      "train loss:0.02844603711951795\n",
      "train loss:0.10212313775892387\n",
      "train loss:0.08355033194832417\n",
      "train loss:0.06261305484975671\n",
      "train loss:0.035142504792912865\n",
      "train loss:0.040156661324447604\n",
      "train loss:0.01939108917213222\n",
      "train loss:0.03292807415541812\n",
      "train loss:0.05758404274357115\n",
      "train loss:0.02452433691880791\n",
      "train loss:0.025190629139166303\n",
      "train loss:0.028944281290943147\n",
      "train loss:0.03774454966749764\n",
      "train loss:0.028839843541891126\n",
      "train loss:0.03620892687499965\n",
      "train loss:0.05685293638155633\n",
      "train loss:0.015082662564473428\n",
      "train loss:0.023702376625139392\n",
      "train loss:0.01788250889347222\n",
      "train loss:0.021102899833554224\n",
      "train loss:0.08796296313848267\n",
      "train loss:0.02430088716269017\n",
      "train loss:0.03942232298680268\n",
      "train loss:0.016445414655417757\n",
      "train loss:0.029057485990444273\n",
      "train loss:0.031784954652749865\n",
      "train loss:0.02655037612656825\n",
      "train loss:0.024224384630944548\n",
      "train loss:0.011416463076236822\n",
      "=== epoch:3, train acc:0.979, test acc:0.95 ===\n",
      "train loss:0.037642565492608714\n",
      "train loss:0.028728767046927582\n",
      "train loss:0.015886219305612757\n",
      "train loss:0.010957851723564737\n",
      "train loss:0.02348192781299127\n",
      "train loss:0.018162672279621043\n",
      "train loss:0.049269627909044135\n",
      "train loss:0.0140347073264504\n",
      "train loss:0.02220586244390448\n",
      "train loss:0.010738180406471214\n",
      "train loss:0.03663172957841579\n",
      "train loss:0.01889335822958239\n",
      "train loss:0.03616617154159706\n",
      "train loss:0.013997226798250724\n",
      "train loss:0.027352512331249287\n",
      "train loss:0.049372732928772145\n",
      "train loss:0.06970172077682667\n",
      "train loss:0.03431149198491629\n",
      "train loss:0.021440536655370764\n",
      "train loss:0.023833802636741265\n",
      "train loss:0.01982191133257835\n",
      "train loss:0.01781087143808357\n",
      "train loss:0.1569953657082196\n",
      "train loss:0.03506274173952181\n",
      "train loss:0.010034779414308297\n",
      "train loss:0.013666093227134553\n",
      "train loss:0.026860384406743452\n",
      "train loss:0.05132968883307161\n",
      "train loss:0.04416406734107166\n",
      "train loss:0.007622909555867569\n",
      "train loss:0.020603413024484447\n",
      "train loss:0.008549012956731834\n",
      "train loss:0.05852645086939526\n",
      "train loss:0.015945180536897804\n",
      "train loss:0.013328308455242638\n",
      "train loss:0.0324714362854509\n",
      "train loss:0.020456159126113253\n",
      "train loss:0.014232894256098774\n",
      "train loss:0.009884442634659197\n",
      "train loss:0.01971295663870394\n",
      "train loss:0.007017889453550114\n",
      "train loss:0.022943883601255193\n",
      "train loss:0.03890644632549208\n",
      "train loss:0.017247279975032746\n",
      "train loss:0.015251384213660306\n",
      "train loss:0.016292408780445772\n",
      "train loss:0.0068200084892317756\n",
      "train loss:0.0102304489342431\n",
      "train loss:0.016500037644325737\n",
      "train loss:0.009260513241825946\n",
      "=== epoch:4, train acc:0.976, test acc:0.956 ===\n",
      "train loss:0.009684790098769233\n",
      "train loss:0.017307996888271917\n",
      "train loss:0.009502174422845882\n",
      "train loss:0.0110076605152367\n",
      "train loss:0.0400294329615102\n",
      "train loss:0.015138739854986833\n",
      "train loss:0.01689462432111116\n",
      "train loss:0.029988640313055898\n",
      "train loss:0.024062063560958403\n",
      "train loss:0.011324414598174208\n",
      "train loss:0.010315141132575307\n",
      "train loss:0.026293515559475872\n",
      "train loss:0.0097962680596026\n",
      "train loss:0.018193427720282124\n",
      "train loss:0.0155193292342391\n",
      "train loss:0.008985548242596413\n",
      "train loss:0.007206611404640385\n",
      "train loss:0.009314384280478729\n",
      "train loss:0.016886482566698845\n",
      "train loss:0.01558068394574192\n",
      "train loss:0.014185441416718266\n",
      "train loss:0.0064473723529783755\n",
      "train loss:0.008371990216958607\n",
      "train loss:0.010471884743126117\n",
      "train loss:0.009367861713695998\n",
      "train loss:0.008975985580465971\n",
      "train loss:0.012715971517021888\n",
      "train loss:0.01225487348699951\n",
      "train loss:0.017777627821576995\n",
      "train loss:0.016186238174660864\n",
      "train loss:0.005740310395894027\n",
      "train loss:0.020069254078347573\n",
      "train loss:0.01963047406090883\n",
      "train loss:0.014070242923188979\n",
      "train loss:0.0329265989890546\n",
      "train loss:0.014855059828101747\n",
      "train loss:0.011765509034775926\n",
      "train loss:0.007415507421377311\n",
      "train loss:0.007979583390104811\n",
      "train loss:0.008564384658353496\n",
      "train loss:0.011406844349350378\n",
      "train loss:0.02293007196611285\n",
      "train loss:0.007379762134817731\n",
      "train loss:0.010427360687008136\n",
      "train loss:0.020761103849134682\n",
      "train loss:0.015090830896518873\n",
      "train loss:0.01038659050038642\n",
      "train loss:0.011162464736796822\n",
      "train loss:0.007837150387787855\n",
      "train loss:0.030238330447587967\n",
      "=== epoch:5, train acc:0.98, test acc:0.938 ===\n",
      "train loss:0.007771282514503715\n",
      "train loss:0.007559195370881087\n",
      "train loss:0.009377375510506434\n",
      "train loss:0.0315565437486307\n",
      "train loss:0.006851579400269625\n",
      "train loss:0.011029980622194934\n",
      "train loss:0.012009203447331085\n",
      "train loss:0.005466742109022375\n",
      "train loss:0.0101816304485774\n",
      "train loss:0.033192851619783637\n",
      "train loss:0.008081187462617323\n",
      "train loss:0.01432631827770399\n",
      "train loss:0.0075645472002087745\n",
      "train loss:0.0143429965535273\n",
      "train loss:0.024922171163700085\n",
      "train loss:0.007605530005316514\n",
      "train loss:0.021259696470320937\n",
      "train loss:0.015251326698561435\n",
      "train loss:0.007323016376094759\n",
      "train loss:0.006436335919788284\n",
      "train loss:0.01162663027553494\n",
      "train loss:0.03606563294575178\n",
      "train loss:0.020328543545413212\n",
      "train loss:0.014258180915418367\n",
      "train loss:0.0057577000406145665\n",
      "train loss:0.007304274388116055\n",
      "train loss:0.005155763143096123\n",
      "train loss:0.004099162977339712\n",
      "train loss:0.009376546098650313\n",
      "train loss:0.018395502456327907\n",
      "train loss:0.010617248317266108\n",
      "train loss:0.004902832962885118\n",
      "train loss:0.012110128958802304\n",
      "train loss:0.013262443029596773\n",
      "train loss:0.014431795506714624\n",
      "train loss:0.0058088653787979365\n",
      "train loss:0.0029710986937883555\n",
      "train loss:0.005433644708393673\n",
      "train loss:0.005099086237511306\n",
      "train loss:0.004741760326724842\n",
      "train loss:0.00590023279475899\n",
      "train loss:0.01300357690297756\n",
      "train loss:0.007502906122855218\n",
      "train loss:0.004211395836275767\n",
      "train loss:0.005563584639452929\n",
      "train loss:0.006060252263804198\n",
      "train loss:0.005163704772928904\n",
      "train loss:0.038160689098943\n",
      "train loss:0.006755375564189933\n",
      "train loss:0.00520178968252621\n",
      "=== epoch:6, train acc:0.99, test acc:0.964 ===\n",
      "train loss:0.006775588562316601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005840344884075765\n",
      "train loss:0.004925927021607774\n",
      "train loss:0.008884597787731539\n",
      "train loss:0.0045572663572985206\n",
      "train loss:0.005383145997238195\n",
      "train loss:0.0064644403584146306\n",
      "train loss:0.005383572872500242\n",
      "train loss:0.00845458377290172\n",
      "train loss:0.006091046825701146\n",
      "train loss:0.003270659524471875\n",
      "train loss:0.008841594774362138\n",
      "train loss:0.010018005745273055\n",
      "train loss:0.007218282233967315\n",
      "train loss:0.006688847097042693\n",
      "train loss:0.018817777383251414\n",
      "train loss:0.0050890749808219\n",
      "train loss:0.008279538927433902\n",
      "train loss:0.003213739109636578\n",
      "train loss:0.002473037353773249\n",
      "train loss:0.003305064394444406\n",
      "train loss:0.005817843340590443\n",
      "train loss:0.002975191308631981\n",
      "train loss:0.003995847529218161\n",
      "train loss:0.002388198155893248\n",
      "train loss:0.0036293702961610833\n",
      "train loss:0.00593221640808338\n",
      "train loss:0.0034233836890216747\n",
      "train loss:0.0036339796794254892\n",
      "train loss:0.003896027765728834\n",
      "train loss:0.004136046400762341\n",
      "train loss:0.0036210809408535128\n",
      "train loss:0.004882821184396923\n",
      "train loss:0.00584498970374357\n",
      "train loss:0.0026725659481485614\n",
      "train loss:0.0031098743596286367\n",
      "train loss:0.004308832784591473\n",
      "train loss:0.0060808414187551564\n",
      "train loss:0.004328467061367342\n",
      "train loss:0.0029832058788738947\n",
      "train loss:0.01602880957837777\n",
      "train loss:0.005410431403836021\n",
      "train loss:0.0035666320688822833\n",
      "train loss:0.003457347221696781\n",
      "train loss:0.0029054817869482307\n",
      "train loss:0.00811171325606095\n",
      "train loss:0.0027030390301563557\n",
      "train loss:0.0032071336624488332\n",
      "train loss:0.0027759180422367636\n",
      "train loss:0.002703260677726537\n",
      "=== epoch:7, train acc:0.995, test acc:0.96 ===\n",
      "train loss:0.003916583769916397\n",
      "train loss:0.008551766829191393\n",
      "train loss:0.0025764032755027587\n",
      "train loss:0.004405793215031198\n",
      "train loss:0.0028707590502722474\n",
      "train loss:0.0050373067709146855\n",
      "train loss:0.0015453280156065166\n",
      "train loss:0.004407605381652369\n",
      "train loss:0.005154239005700462\n",
      "train loss:0.004675222243005864\n",
      "train loss:0.004844621577805915\n",
      "train loss:0.0030889480591999884\n",
      "train loss:0.007538626124452633\n",
      "train loss:0.003210784659543174\n",
      "train loss:0.0034864220345626486\n",
      "train loss:0.0017495366322539448\n",
      "train loss:0.008549197642024456\n",
      "train loss:0.0041830820383875235\n",
      "train loss:0.0057215337197083615\n",
      "train loss:0.0032677382035674733\n",
      "train loss:0.0064083626550890775\n",
      "train loss:0.0013665583985835795\n",
      "train loss:0.0041600068683551586\n",
      "train loss:0.0018141993477583938\n",
      "train loss:0.0037044814567096045\n",
      "train loss:0.014678011350346102\n",
      "train loss:0.0015953313037727448\n",
      "train loss:0.12464731823484267\n",
      "train loss:0.004394142387929905\n",
      "train loss:0.004220346621652782\n",
      "train loss:0.0019285377278897373\n",
      "train loss:0.002037708966331644\n",
      "train loss:0.01022985644025825\n",
      "train loss:0.0027438957782162177\n",
      "train loss:0.0019939371661633824\n",
      "train loss:0.004874123403489948\n",
      "train loss:0.007650867798395713\n",
      "train loss:0.0032076251254433523\n",
      "train loss:0.004112935602146568\n",
      "train loss:0.0027089828751858352\n",
      "train loss:0.003174475847936196\n",
      "train loss:0.002866793104126537\n",
      "train loss:0.004161506956110823\n",
      "train loss:0.005345141105053252\n",
      "train loss:0.002416305958086177\n",
      "train loss:0.015033281362458215\n",
      "train loss:0.0038341030505522787\n",
      "train loss:0.008615176876471016\n",
      "train loss:0.012402913357690585\n",
      "train loss:0.0023823933555890495\n",
      "=== epoch:8, train acc:0.994, test acc:0.959 ===\n",
      "train loss:0.0017465367860757279\n",
      "train loss:0.002500329101902716\n",
      "train loss:0.003083524971685108\n",
      "train loss:0.000754653849141464\n",
      "train loss:0.004300919598684649\n",
      "train loss:0.002557596629962796\n",
      "train loss:0.004301736708435199\n",
      "train loss:0.004467560864179483\n",
      "train loss:0.0015104986970916107\n",
      "train loss:0.0021389895368991623\n",
      "train loss:0.0024008207064767956\n",
      "train loss:0.0017384914859112735\n",
      "train loss:0.0011937496561155092\n",
      "train loss:0.01263305330637726\n",
      "train loss:0.002263584881003943\n",
      "train loss:0.0016598748369075916\n",
      "train loss:0.010525817116882386\n",
      "train loss:0.010708371285139623\n",
      "train loss:0.002571129328594179\n",
      "train loss:0.001638122309251709\n",
      "train loss:0.010330836929471216\n",
      "train loss:0.0012573966099470202\n",
      "train loss:0.005609417425664203\n",
      "train loss:0.0017197942427040868\n",
      "train loss:0.002060559051665001\n",
      "train loss:0.025784163197302618\n",
      "train loss:0.001161328536529233\n",
      "train loss:0.015331915407601118\n",
      "train loss:0.006799555579808289\n",
      "train loss:0.0019972808669672525\n",
      "train loss:0.008559316795600227\n",
      "train loss:0.026143476587584983\n",
      "train loss:0.0019976854889475672\n",
      "train loss:0.003753109052045103\n",
      "train loss:0.011797049668753662\n",
      "train loss:0.05648609030836162\n",
      "train loss:0.002827458794212357\n",
      "train loss:0.005521758770167771\n",
      "train loss:0.0014023238019211792\n",
      "train loss:0.0023976279690851236\n",
      "train loss:0.002191514319840394\n",
      "train loss:0.0037668371435580416\n",
      "train loss:0.0026446784027822786\n",
      "train loss:0.0008446810170048422\n",
      "train loss:0.004992204745002436\n",
      "train loss:0.0018907186211852564\n",
      "train loss:0.008908633639462817\n",
      "train loss:0.001701223147198388\n",
      "train loss:0.0008277029555253134\n",
      "train loss:0.002463004509916148\n",
      "=== epoch:9, train acc:0.999, test acc:0.961 ===\n",
      "train loss:0.0023009728054303635\n",
      "train loss:0.0017210875229527827\n",
      "train loss:0.0017739972986742882\n",
      "train loss:0.0008499510565091066\n",
      "train loss:0.0009253275327274955\n",
      "train loss:0.002941780520474667\n",
      "train loss:0.0016409789291642726\n",
      "train loss:0.0011581045972881116\n",
      "train loss:0.0010931885190547538\n",
      "train loss:0.0013198965229197375\n",
      "train loss:0.003458185289180017\n",
      "train loss:0.0030045194264463034\n",
      "train loss:0.0020193274404078335\n",
      "train loss:0.003798807023330065\n",
      "train loss:0.0014243065143896812\n",
      "train loss:0.0011726227178124396\n",
      "train loss:0.0034822820106151006\n",
      "train loss:0.0010475652242199747\n",
      "train loss:0.0006256446903241932\n",
      "train loss:0.020634623802902163\n",
      "train loss:0.00561356671508591\n",
      "train loss:0.07131760821082189\n",
      "train loss:0.31121284026450974\n",
      "train loss:2.385658328705358\n",
      "train loss:0.6602677723064619\n",
      "train loss:0.04137759436771253\n",
      "train loss:0.005796642315953422\n",
      "train loss:0.007802724381826528\n",
      "train loss:0.006103457146550908\n",
      "train loss:0.016205828877796463\n",
      "train loss:0.020646847128761175\n",
      "train loss:0.008055708959763493\n",
      "train loss:0.008401278524319431\n",
      "train loss:0.01822252911240148\n",
      "train loss:0.013231828432726292\n",
      "train loss:0.009637140265686411\n",
      "train loss:0.006308414009505473\n",
      "train loss:0.011484161085196785\n",
      "train loss:0.010898008015453455\n",
      "train loss:0.014457181397664292\n",
      "train loss:0.007706858075581206\n",
      "train loss:0.005969465444083725\n",
      "train loss:0.011283671041231092\n",
      "train loss:0.006898693133414614\n",
      "train loss:0.007941909072695472\n",
      "train loss:0.006564512469814086\n",
      "train loss:0.004784337060610795\n",
      "train loss:0.00461295136780265\n",
      "train loss:0.005311493534634905\n",
      "train loss:0.00689183745333052\n",
      "=== epoch:10, train acc:0.995, test acc:0.956 ===\n",
      "train loss:0.00656851566078557\n",
      "train loss:0.004384889019598995\n",
      "train loss:0.014227731525503867\n",
      "train loss:0.00386151127899617\n",
      "train loss:0.0069029882338213465\n",
      "train loss:0.003444057121327605\n",
      "train loss:0.006864335706451432\n",
      "train loss:0.0039792538681500695\n",
      "train loss:0.003957534875873364\n",
      "train loss:0.0029899349831860812\n",
      "train loss:0.003178166884767991\n",
      "train loss:0.0037471248568980453\n",
      "train loss:0.00695573762225455\n",
      "train loss:0.005227897574861379\n",
      "train loss:0.004076482215451434\n",
      "train loss:0.0029264003796246846\n",
      "train loss:0.004004729027329186\n",
      "train loss:0.006864860056670311\n",
      "train loss:0.0014438772737563638\n",
      "train loss:0.0034762263515392424\n",
      "train loss:0.0045880304093527\n",
      "train loss:0.003679847592035718\n",
      "train loss:0.008463660799073817\n",
      "train loss:0.002449407791619205\n",
      "train loss:0.004098822600714331\n",
      "train loss:0.00394203249831968\n",
      "train loss:0.002504568823241947\n",
      "train loss:0.002674149505709977\n",
      "train loss:0.004044006405324177\n",
      "train loss:0.0021275215972964483\n",
      "train loss:0.0024891209108644126\n",
      "train loss:0.001978708531276568\n",
      "train loss:0.0031890234517292617\n",
      "train loss:0.004380764256521951\n",
      "train loss:0.0029715905107847913\n",
      "train loss:0.002532334571793733\n",
      "train loss:0.00168258902561362\n",
      "train loss:0.0037103927066613964\n",
      "train loss:0.002549342654470205\n",
      "train loss:0.0023336666771826544\n",
      "train loss:0.0029469437311875003\n",
      "train loss:0.0021502091949481238\n",
      "train loss:0.002167077250024488\n",
      "train loss:0.0025532804098939614\n",
      "train loss:0.001513454145145125\n",
      "train loss:0.002945197257082865\n",
      "train loss:0.002196695973419983\n",
      "train loss:0.0019355614415672842\n",
      "train loss:0.0012605621654029303\n",
      "train loss:0.001049562440894807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:11, train acc:1.0, test acc:0.964 ===\n",
      "train loss:0.008688697572200406\n",
      "train loss:0.005532050780942071\n",
      "train loss:0.0007763629498108809\n",
      "train loss:0.003180953316847498\n",
      "train loss:0.0033077171090705065\n",
      "train loss:0.0014838393134698105\n",
      "train loss:0.0037172950709101127\n",
      "train loss:0.0013787763011887883\n",
      "train loss:0.0010042210181897694\n",
      "train loss:0.0020391751609631264\n",
      "train loss:0.0028514842271341653\n",
      "train loss:0.002599266923578931\n",
      "train loss:0.0019487666058912508\n",
      "train loss:0.001874191369491942\n",
      "train loss:0.0008395293398233203\n",
      "train loss:0.0006287672890684099\n",
      "train loss:0.0018219792637964702\n",
      "train loss:0.002665111098088383\n",
      "train loss:0.001851083431306107\n",
      "train loss:0.0007835470890927859\n",
      "train loss:0.001253151618387987\n",
      "train loss:0.0012536141782151504\n",
      "train loss:0.0015099561232412035\n",
      "train loss:0.0012983029687800391\n",
      "train loss:0.002321413045959735\n",
      "train loss:0.001032649845743206\n",
      "train loss:0.001611488385532817\n",
      "train loss:0.0014365355450808544\n",
      "train loss:0.0014732197642122011\n",
      "train loss:0.001189952843986245\n",
      "train loss:0.0018735495515528494\n",
      "train loss:0.0011334452820025737\n",
      "train loss:0.0014979276122139206\n",
      "train loss:0.0012937003148300367\n",
      "train loss:0.0006827990858992874\n",
      "train loss:0.001080563715030225\n",
      "train loss:0.002300729817105199\n",
      "train loss:0.0011691277548303686\n",
      "train loss:0.0010181705077373455\n",
      "train loss:0.0013105037754642152\n",
      "train loss:0.00110432986189396\n",
      "train loss:0.0011825413439466895\n",
      "train loss:0.0011426196491141675\n",
      "train loss:0.0006244854725465568\n",
      "train loss:0.00084998752879807\n",
      "train loss:0.0014298694669486248\n",
      "train loss:0.0011606472763010954\n",
      "train loss:0.0007871980099328946\n",
      "train loss:0.0007576737420789065\n",
      "train loss:0.0010303601677385634\n",
      "=== epoch:12, train acc:1.0, test acc:0.966 ===\n",
      "train loss:0.0007824551020703177\n",
      "train loss:0.0006720525932507411\n",
      "train loss:0.001983174992933356\n",
      "train loss:0.01195846050543334\n",
      "train loss:0.0010443049844216506\n",
      "train loss:0.0010741434459115387\n",
      "train loss:0.0011278913546630637\n",
      "train loss:0.001018326033070581\n",
      "train loss:0.0010088816293277606\n",
      "train loss:0.0007787792835199679\n",
      "train loss:0.0007186932411429452\n",
      "train loss:0.0010332175131461425\n",
      "train loss:0.0007963180449044886\n",
      "train loss:0.0005123827252341796\n",
      "train loss:0.00036941833257133505\n",
      "train loss:0.0012743935687011263\n",
      "train loss:0.0006173357193453162\n",
      "train loss:0.0007543406609696268\n",
      "train loss:0.0007242769655153507\n",
      "train loss:0.00047044097071302594\n",
      "train loss:0.0005697594871518839\n",
      "train loss:0.0006036435890421185\n",
      "train loss:0.0007248331881164133\n",
      "train loss:0.0011257158284993397\n",
      "train loss:0.00045746479828640945\n",
      "train loss:0.0020419639501881295\n",
      "train loss:0.00046999711317240975\n",
      "train loss:0.0012233812146557682\n",
      "train loss:0.0011526168851729627\n",
      "train loss:0.0008809386410436144\n",
      "train loss:0.0003171290126533182\n",
      "train loss:0.0008285432339721943\n",
      "train loss:0.0004973901325803017\n",
      "train loss:0.0013142815313326548\n",
      "train loss:0.0008173658113551427\n",
      "train loss:0.0007999828045129262\n",
      "train loss:0.0015835192188722192\n",
      "train loss:0.00038059721247539604\n",
      "train loss:0.0006320823966310942\n",
      "train loss:0.0011230977780120567\n",
      "train loss:0.0017114028958944904\n",
      "train loss:0.001038264977817447\n",
      "train loss:0.0009339983018362464\n",
      "train loss:0.0007918744584809349\n",
      "train loss:0.0006403034435881408\n",
      "train loss:0.0006765707256975793\n",
      "train loss:0.0005584579183232341\n",
      "train loss:0.0006988590495197565\n",
      "train loss:0.0005895952330065525\n",
      "train loss:0.0004286881787709046\n",
      "=== epoch:13, train acc:1.0, test acc:0.962 ===\n",
      "train loss:0.0003651162969394103\n",
      "train loss:0.0006144885401242327\n",
      "train loss:0.0005954828171799025\n",
      "train loss:0.001090407998526736\n",
      "train loss:0.0003977922788186142\n",
      "train loss:0.0007642621354839986\n",
      "train loss:0.0004478069572074094\n",
      "train loss:0.00047900559288374987\n",
      "train loss:0.0003191912109662183\n",
      "train loss:0.001601364689999249\n",
      "train loss:0.0007126489283912177\n",
      "train loss:0.0006236199096475329\n",
      "train loss:0.0005116403632133052\n",
      "train loss:0.0006202427626352252\n",
      "train loss:0.0005834612095680412\n",
      "train loss:0.0010817037880006082\n",
      "train loss:0.0002824112232518155\n",
      "train loss:0.0006750423505547586\n",
      "train loss:0.000544372518790218\n",
      "train loss:0.0006671672767088586\n",
      "train loss:0.0008024954852207868\n",
      "train loss:0.0003546857008926952\n",
      "train loss:0.0010457669659189222\n",
      "train loss:0.0005062100278333811\n",
      "train loss:0.0008695797821752925\n",
      "train loss:0.0007293821460128017\n",
      "train loss:0.0004911297937380579\n",
      "train loss:0.0003700498435450103\n",
      "train loss:0.0019597693416732037\n",
      "train loss:0.00046645491460810094\n",
      "train loss:0.0007176888983635296\n",
      "train loss:0.0010444272469718949\n",
      "train loss:0.0006083716927243006\n",
      "train loss:0.0004637088705769959\n",
      "train loss:0.0005330544766679602\n",
      "train loss:0.00048520411926827336\n",
      "train loss:0.00047135475624423146\n",
      "train loss:0.000468076342899241\n",
      "train loss:0.00046909296909399987\n",
      "train loss:0.00031034860960476923\n",
      "train loss:0.0001896324383641716\n",
      "train loss:0.0006386438854433378\n",
      "train loss:0.00018315722162312887\n",
      "train loss:0.0007393743895830797\n",
      "train loss:0.00034918697084575364\n",
      "train loss:0.0004937206572290163\n",
      "train loss:0.00024412284953034398\n",
      "train loss:0.0005655847918745267\n",
      "train loss:0.0006232953994482664\n",
      "train loss:0.00028012028511358825\n",
      "=== epoch:14, train acc:1.0, test acc:0.964 ===\n",
      "train loss:0.00038121624371741846\n",
      "train loss:0.0006877683047234963\n",
      "train loss:0.000522934610035678\n",
      "train loss:0.00013774454873921848\n",
      "train loss:0.0013426832791029772\n",
      "train loss:0.00022456480617905002\n",
      "train loss:0.001222895219198442\n",
      "train loss:0.0004303955953846434\n",
      "train loss:0.0005578098044359362\n",
      "train loss:0.00018589052407163204\n",
      "train loss:0.0004510324044716595\n",
      "train loss:0.00042405176828604714\n",
      "train loss:0.00028789914326852925\n",
      "train loss:0.0003205981344572908\n",
      "train loss:0.00028905715352527497\n",
      "train loss:0.00016202875399681487\n",
      "train loss:0.0002876207573515057\n",
      "train loss:0.00048135544917050866\n",
      "train loss:0.00014354871618090184\n",
      "train loss:0.0003556112918230612\n",
      "train loss:0.00018221607110651035\n",
      "train loss:0.0005186853654261936\n",
      "train loss:0.0006087184769091596\n",
      "train loss:0.00023463628006045707\n",
      "train loss:0.0002769305558047778\n",
      "train loss:0.08297964081804039\n",
      "train loss:0.049255385191282156\n",
      "train loss:0.021828381960158218\n",
      "train loss:0.0001703779345973308\n",
      "train loss:0.0002488545656104161\n",
      "train loss:0.0010152240492874887\n",
      "train loss:0.00021875304897521955\n",
      "train loss:0.4040911232187849\n",
      "train loss:1.11110238821662\n",
      "train loss:0.345049724878464\n",
      "train loss:0.08649935414340332\n",
      "train loss:0.011927575373704868\n",
      "train loss:0.2594768029091375\n",
      "train loss:0.019698019270289083\n",
      "train loss:0.15114925092358886\n",
      "train loss:0.26210508010147593\n",
      "train loss:0.022375668990016154\n",
      "train loss:0.007447218974100166\n",
      "train loss:0.008684440499494777\n",
      "train loss:0.010264824056416131\n",
      "train loss:0.00606297853728597\n",
      "train loss:0.005705131773738681\n",
      "train loss:0.004894064537699753\n",
      "train loss:0.004452838858096343\n",
      "train loss:0.0018370871794046268\n",
      "=== epoch:15, train acc:0.991, test acc:0.951 ===\n",
      "train loss:0.006081303234235542\n",
      "train loss:0.00490732051119937\n",
      "train loss:0.002487021327780228\n",
      "train loss:0.0035006433848183294\n",
      "train loss:0.0020535290624835293\n",
      "train loss:0.0028407470531524514\n",
      "train loss:0.002971361547746556\n",
      "train loss:0.0025258614928093583\n",
      "train loss:0.0017821920024850702\n",
      "train loss:0.005102253178500798\n",
      "train loss:0.0020844803716803017\n",
      "train loss:0.005232430436581861\n",
      "train loss:0.0016738890825612517\n",
      "train loss:0.0010840864660847046\n",
      "train loss:0.003160816323943541\n",
      "train loss:0.0020111622620020407\n",
      "train loss:0.0015255039832838112\n",
      "train loss:0.0012277820348894624\n",
      "train loss:0.0014345199535822405\n",
      "train loss:0.0015871633917882105\n",
      "train loss:0.0020883293085665593\n",
      "train loss:0.0012361879183536816\n",
      "train loss:0.0015741082676581902\n",
      "train loss:0.0009472659176079149\n",
      "train loss:0.001685318380342361\n",
      "train loss:0.0014495285535457813\n",
      "train loss:0.004258463462695734\n",
      "train loss:0.0007736473580664593\n",
      "train loss:0.0031746465313390827\n",
      "train loss:0.0021468562705803658\n",
      "train loss:0.0018699275505638675\n",
      "train loss:0.001332655484579196\n",
      "train loss:0.0018489340723198\n",
      "train loss:0.0008643440533718371\n",
      "train loss:0.0010470433359587377\n",
      "train loss:0.0008103047773264555\n",
      "train loss:0.0030378236326728796\n",
      "train loss:0.001366284345504905\n",
      "train loss:0.0009621786739963696\n",
      "train loss:0.0036432433133962183\n",
      "train loss:0.0007968701032290642\n",
      "train loss:0.00042795014743442233\n",
      "train loss:0.0005260889462721618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004045448633793528\n",
      "train loss:0.000721948706603099\n",
      "train loss:0.0027302175775035407\n",
      "train loss:0.001311614991102876\n",
      "train loss:0.003385568835154525\n",
      "train loss:0.12395480869355291\n",
      "train loss:0.06728665407882603\n",
      "=== epoch:16, train acc:0.935, test acc:0.909 ===\n",
      "train loss:0.023690030928011713\n",
      "train loss:0.039013628264277546\n",
      "train loss:0.0015624040193561062\n",
      "train loss:0.032651703171686815\n",
      "train loss:0.0015385040435959454\n",
      "train loss:0.005252675773355677\n",
      "train loss:0.0015497248830898807\n",
      "train loss:0.001075946039319153\n",
      "train loss:0.0018312683715956514\n",
      "train loss:0.001113073596764196\n",
      "train loss:0.0020752257625319525\n",
      "train loss:0.008967287711506162\n",
      "train loss:0.0011274257428940144\n",
      "train loss:0.0026109296977402507\n",
      "train loss:0.0016773513725496683\n",
      "train loss:0.0013790989343063038\n",
      "train loss:0.001767954860952375\n",
      "train loss:0.0010502489343552925\n",
      "train loss:0.001397879197178221\n",
      "train loss:0.0014410925296240965\n",
      "train loss:0.01127339598317877\n",
      "train loss:0.044843727779871154\n",
      "train loss:0.029396149652512058\n",
      "train loss:0.011580559787277228\n",
      "train loss:0.002314478526446982\n",
      "train loss:0.0028046994021059413\n",
      "train loss:0.0010753632327314057\n",
      "train loss:0.000661034644707268\n",
      "train loss:0.0008395648309952225\n",
      "train loss:0.0010759637098635656\n",
      "train loss:0.0010614436329053724\n",
      "train loss:0.0014077791355673213\n",
      "train loss:0.0015493144496584652\n",
      "train loss:0.0016041669798658852\n",
      "train loss:0.00279969945798251\n",
      "train loss:0.0016171065764337194\n",
      "train loss:0.0009748336411257194\n",
      "train loss:0.0012954140929980127\n",
      "train loss:0.0018498629784385271\n",
      "train loss:0.0012057690082451146\n",
      "train loss:0.0015562579264271513\n",
      "train loss:0.0006837991693623916\n",
      "train loss:0.0010136628750132674\n",
      "train loss:0.0011640807458564507\n",
      "train loss:0.0013986102025774299\n",
      "train loss:0.0024813565427404417\n",
      "train loss:0.000790445354654032\n",
      "train loss:0.001127980175550965\n",
      "train loss:0.0007589295817734965\n",
      "train loss:0.0008359261851721123\n",
      "=== epoch:17, train acc:0.998, test acc:0.964 ===\n",
      "train loss:0.0007443363656203907\n",
      "train loss:0.0009802828301443756\n",
      "train loss:0.0015102137191231203\n",
      "train loss:0.002108566522924517\n",
      "train loss:0.0003776825834296034\n",
      "train loss:0.0006310719643596927\n",
      "train loss:0.0008858274226861798\n",
      "train loss:0.00035360521730264794\n",
      "train loss:0.00045085598001349923\n",
      "train loss:0.0005775700761860965\n",
      "train loss:0.0011180611073934603\n",
      "train loss:0.0007805359532493908\n",
      "train loss:0.00046293325730751596\n",
      "train loss:0.00021175913731101299\n",
      "train loss:0.0007947689334702615\n",
      "train loss:0.000509056984868315\n",
      "train loss:0.0005127292301469772\n",
      "train loss:0.0005720518821039317\n",
      "train loss:0.00029221804137377877\n",
      "train loss:0.0005005035074631617\n",
      "train loss:0.000416480035597302\n",
      "train loss:0.0007205534857936237\n",
      "train loss:0.0003880115780094493\n",
      "train loss:0.00041329497040856435\n",
      "train loss:0.0007837186797100527\n",
      "train loss:0.000431298757082106\n",
      "train loss:0.00036600944864925917\n",
      "train loss:0.0005067399913911262\n",
      "train loss:0.0007408056032873333\n",
      "train loss:0.00023702797430111971\n",
      "train loss:0.000544103044721691\n",
      "train loss:6.592925891815165e-05\n",
      "train loss:0.00027972486082719714\n",
      "train loss:0.0004256246901700002\n",
      "train loss:0.0006813754407023841\n",
      "train loss:0.00042051038774228904\n",
      "train loss:0.0003106338937607641\n",
      "train loss:0.0003594949541996318\n",
      "train loss:0.0003068673021664929\n",
      "train loss:0.0004997712166627499\n",
      "train loss:0.0004960327783477405\n",
      "train loss:0.00017947776277674272\n",
      "train loss:0.0002530839356480889\n",
      "train loss:0.0004903917341492252\n",
      "train loss:5.0979268890584285e-05\n",
      "train loss:0.00044434717325388064\n",
      "train loss:0.0005139063503522496\n",
      "train loss:0.00026506426008183624\n",
      "train loss:0.00033888295090848925\n",
      "train loss:0.00035802850625096566\n",
      "=== epoch:18, train acc:0.999, test acc:0.967 ===\n",
      "train loss:0.00044390561062630893\n",
      "train loss:0.00026149823006020297\n",
      "train loss:0.0002893747680722515\n",
      "train loss:0.00029368329920002054\n",
      "train loss:0.000529040672889761\n",
      "train loss:0.00021772758779003173\n",
      "train loss:0.00028769262074650296\n",
      "train loss:0.00019037466890874785\n",
      "train loss:0.0001499194148892501\n",
      "train loss:0.0003315200223894846\n",
      "train loss:8.421372108802995e-05\n",
      "train loss:0.00032798473206347616\n",
      "train loss:0.0003609204884422594\n",
      "train loss:0.00012944468491110555\n",
      "train loss:0.00023789414588557304\n",
      "train loss:6.20401675052975e-05\n",
      "train loss:0.00012260044843717238\n",
      "train loss:0.00021790528176499375\n",
      "train loss:0.0007246851774561368\n",
      "train loss:0.00018875072323768313\n",
      "train loss:0.0002505899724331926\n",
      "train loss:0.0002191032343284484\n",
      "train loss:0.00029625036814742023\n",
      "train loss:6.809435775726267e-05\n",
      "train loss:6.108560181881131e-05\n",
      "train loss:0.0002149058106366203\n",
      "train loss:0.0005744368390333768\n",
      "train loss:0.00020015874439938106\n",
      "train loss:0.0001074503789027473\n",
      "train loss:0.0002638050389489647\n",
      "train loss:0.00021481161136212385\n",
      "train loss:0.00020647834005253885\n",
      "train loss:0.0001728928295748098\n",
      "train loss:0.0002561201120872726\n",
      "train loss:0.00015461356986640033\n",
      "train loss:0.00016748474307714923\n",
      "train loss:5.013655495184756e-05\n",
      "train loss:0.0003856717094200161\n",
      "train loss:6.125002530010408e-05\n",
      "train loss:0.00029422864157798253\n",
      "train loss:0.00024028707311672543\n",
      "train loss:0.00018773603770751631\n",
      "train loss:0.0005324961474751699\n",
      "train loss:0.00015947688605474686\n",
      "train loss:0.0001324627621874016\n",
      "train loss:0.00024956573529676866\n",
      "train loss:0.00044110928384870617\n",
      "train loss:4.4478883330413254e-05\n",
      "train loss:0.00015645482237510545\n",
      "train loss:0.00014111200448349326\n",
      "=== epoch:19, train acc:0.999, test acc:0.968 ===\n",
      "train loss:0.0002173752242920383\n",
      "train loss:0.0005950260056450361\n",
      "train loss:0.0002683622734064314\n",
      "train loss:0.00019971075315770533\n",
      "train loss:0.00022681740809186578\n",
      "train loss:0.00012056008335032611\n",
      "train loss:0.00010830229807765275\n",
      "train loss:8.542699709414139e-05\n",
      "train loss:0.0002270269310476199\n",
      "train loss:0.00012992382414526434\n",
      "train loss:0.0002677185658411689\n",
      "train loss:0.0002234140038504844\n",
      "train loss:0.24467228186960863\n",
      "train loss:0.0366732910797826\n",
      "train loss:0.08089467407990439\n",
      "train loss:0.12214480600628833\n",
      "train loss:0.09099588163454887\n",
      "train loss:0.2705600365442614\n",
      "train loss:0.3929762623673108\n",
      "train loss:0.10769371441177884\n",
      "train loss:0.15341422654072015\n",
      "train loss:0.031049812987463343\n",
      "train loss:0.0008845630087709315\n",
      "train loss:0.0023891226989470687\n",
      "train loss:0.0006690214568302342\n",
      "train loss:0.000773438462591163\n",
      "train loss:0.0007140865886683281\n",
      "train loss:0.0005989261644463322\n",
      "train loss:0.0012127078492633705\n",
      "train loss:0.06554589171449955\n",
      "train loss:0.009140942771710514\n",
      "train loss:0.0039569448392184625\n",
      "train loss:0.0009169589399643667\n",
      "train loss:0.0014443422875206951\n",
      "train loss:0.0004159621772498806\n",
      "train loss:0.00406605205584865\n",
      "train loss:0.00038602907761249957\n",
      "train loss:0.004480698580668244\n",
      "train loss:0.0005373091046324746\n",
      "train loss:0.0002695650037401382\n",
      "train loss:0.000782341629349507\n",
      "train loss:0.006561377256824652\n",
      "train loss:0.0012739858319177236\n",
      "train loss:0.00034730681721607614\n",
      "train loss:0.0012029753257823859\n",
      "train loss:0.0008066676625587569\n",
      "train loss:0.0006054678437176554\n",
      "train loss:0.00012947877131667647\n",
      "train loss:0.000740575962975713\n",
      "train loss:0.0005973641650984071\n",
      "=== epoch:20, train acc:0.999, test acc:0.963 ===\n",
      "train loss:0.0009812403566811566\n",
      "train loss:0.00036925255227441027\n",
      "train loss:0.0006507764249815823\n",
      "train loss:0.0006579557200527249\n",
      "train loss:0.0007290989173214515\n",
      "train loss:0.0007585913980403641\n",
      "train loss:0.0015862876001209226\n",
      "train loss:0.000242894261644186\n",
      "train loss:0.0008864197498795469\n",
      "train loss:0.0006390602224121991\n",
      "train loss:0.0005473091632580491\n",
      "train loss:0.00037971182380360543\n",
      "train loss:0.0005449576222630286\n",
      "train loss:0.00019167741336514814\n",
      "train loss:0.0009922496915649366\n",
      "train loss:0.00028400662639266555\n",
      "train loss:0.0004144756700855274\n",
      "train loss:0.0002766790091972152\n",
      "train loss:0.0005621490728342645\n",
      "train loss:0.0003521197954838625\n",
      "train loss:0.0018163418445618443\n",
      "train loss:0.0005704425011007227\n",
      "train loss:0.00047409599311698877\n",
      "train loss:0.021307041894842296\n",
      "train loss:0.0005992680212949875\n",
      "train loss:0.00011253860163898936\n",
      "train loss:0.00021106954436360805\n",
      "train loss:0.00013851839881054532\n",
      "train loss:0.00047013337363990506\n",
      "train loss:0.0005300846794943806\n",
      "train loss:9.103640514059917e-05\n",
      "train loss:0.00018086153002932256\n",
      "train loss:8.062094097265412e-05\n",
      "train loss:0.00047898897203040367\n",
      "train loss:0.00023248930243369506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00019024812350557546\n",
      "train loss:0.0002704725784644826\n",
      "train loss:0.0006122258879924613\n",
      "train loss:0.00019540769972456275\n",
      "train loss:0.00028857575184909227\n",
      "train loss:1.815682466186539e-05\n",
      "train loss:0.0002465547410413719\n",
      "train loss:0.0004187716175946672\n",
      "train loss:0.0006101593188117742\n",
      "train loss:4.3945881380574766e-05\n",
      "train loss:0.0001698254876885923\n",
      "train loss:0.0002371880974331457\n",
      "train loss:0.00019983637378507727\n",
      "train loss:0.00013174292195470706\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.959\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "# パラメータの保存\n",
    "network.save_params(opti + \".params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "#plt.yscale(\"log\")\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti='Adam'\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer=opti, optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:3.6264806414560884e-05\n",
      "=== epoch:1, train acc:1.0, test acc:0.959 ===\n",
      "train loss:3.0153050433062577e-05\n",
      "train loss:0.0010544631585995808\n",
      "train loss:0.000481964446187105\n",
      "train loss:0.004617047541684658\n",
      "train loss:0.000631368169142481\n",
      "train loss:0.005349074160783895\n",
      "train loss:0.00561817432812859\n",
      "train loss:0.002095684226647088\n",
      "train loss:0.0007635603250960051\n",
      "train loss:0.000887978645273451\n",
      "train loss:0.00014892040394973857\n",
      "train loss:0.001741205973639997\n",
      "train loss:0.0016228595658497034\n",
      "train loss:0.00016172665059435387\n",
      "train loss:4.358440577774313e-05\n",
      "train loss:0.00015263576199286933\n",
      "train loss:0.0009633925732183299\n",
      "train loss:7.101885565090566e-05\n",
      "train loss:0.00010827754577281775\n",
      "train loss:0.0004027615812932813\n",
      "train loss:4.194669249058599e-05\n",
      "train loss:0.00011219458368906506\n",
      "train loss:2.581274746510891e-05\n",
      "train loss:0.0005180784443388183\n",
      "train loss:0.013695506674552034\n",
      "train loss:0.000753495752238554\n",
      "train loss:0.0006259294888840003\n",
      "train loss:0.00043329043206011877\n",
      "train loss:0.00011016163585858588\n",
      "train loss:0.0003555127470884388\n",
      "train loss:0.00021809201612809227\n",
      "train loss:6.164283816663036e-05\n",
      "train loss:0.00018430042366504644\n",
      "train loss:0.00014642938419965357\n",
      "train loss:5.54164556574718e-05\n",
      "train loss:0.0012613161168534273\n",
      "train loss:0.00017334376745813536\n",
      "train loss:0.00029116333833605567\n",
      "train loss:0.00018026576952738947\n",
      "train loss:9.914857908250082e-05\n",
      "train loss:2.7326708592973562e-05\n",
      "train loss:0.00010154273517152663\n",
      "train loss:6.902217602279869e-05\n",
      "train loss:3.677339024282029e-05\n",
      "train loss:8.642623495102083e-05\n",
      "train loss:0.0001003340923439896\n",
      "train loss:0.00010778380414429214\n",
      "train loss:0.00018722570676843063\n",
      "train loss:0.00012890028861730406\n",
      "train loss:7.476754536659811e-05\n",
      "=== epoch:2, train acc:1.0, test acc:0.963 ===\n",
      "train loss:6.324032479025036e-05\n",
      "train loss:7.360118444798934e-05\n",
      "train loss:8.192104109405423e-05\n",
      "train loss:6.82352343744321e-05\n",
      "train loss:0.0001455468133849145\n",
      "train loss:2.4475435828570172e-05\n",
      "train loss:0.00011228381964931338\n",
      "train loss:0.0002932108970629551\n",
      "train loss:0.00033140244528263564\n",
      "train loss:0.0002840672397865767\n",
      "train loss:7.181148361389006e-05\n",
      "train loss:0.00014357659699383473\n",
      "train loss:0.00013920953211765045\n",
      "train loss:0.0007543523395936475\n",
      "train loss:3.049977934850549e-05\n",
      "train loss:0.0003686725922046276\n",
      "train loss:0.000146754034949447\n",
      "train loss:2.3885953072112373e-05\n",
      "train loss:7.523445178340978e-06\n",
      "train loss:3.7142066644602297e-05\n",
      "train loss:1.3089192836222647e-05\n",
      "train loss:0.0004498612875260843\n",
      "train loss:4.115526419137014e-05\n",
      "train loss:0.00036004198015168916\n",
      "train loss:6.228970463032676e-05\n",
      "train loss:5.0545681921814736e-05\n",
      "train loss:0.00040698273120090935\n",
      "train loss:0.00014503401893290802\n",
      "train loss:7.038250564632814e-05\n",
      "train loss:0.00029575468839625543\n",
      "train loss:7.420953850127976e-05\n",
      "train loss:0.00014856493161907606\n",
      "train loss:0.00011055510044474408\n",
      "train loss:0.00025900892125922686\n",
      "train loss:2.927458009866761e-05\n",
      "train loss:0.00013097601816101635\n",
      "train loss:3.126771699221505e-05\n",
      "train loss:2.235247381224763e-05\n",
      "train loss:9.043683803379394e-05\n",
      "train loss:5.443901574587298e-05\n",
      "train loss:0.00022854475107473573\n",
      "train loss:1.6197317682855924e-05\n",
      "train loss:5.7634032346150136e-05\n",
      "train loss:0.0001093454059865841\n",
      "train loss:4.3597248144888226e-05\n",
      "train loss:0.0006534396926476467\n",
      "train loss:0.00013519513646256383\n",
      "train loss:5.508391819164529e-05\n",
      "train loss:7.973300651509641e-05\n",
      "train loss:1.436427390898988e-05\n",
      "=== epoch:3, train acc:1.0, test acc:0.963 ===\n",
      "train loss:2.863306614646412e-05\n",
      "train loss:0.0002759936449064738\n",
      "train loss:7.510726596566922e-05\n",
      "train loss:0.00022599910755211907\n",
      "train loss:0.00025504934867664347\n",
      "train loss:7.09543163387966e-05\n",
      "train loss:7.885022102943687e-05\n",
      "train loss:1.9269024547594712e-05\n",
      "train loss:3.6615240610379556e-05\n",
      "train loss:2.6580328804807393e-05\n",
      "train loss:6.905423469830633e-05\n",
      "train loss:4.770284490280407e-05\n",
      "train loss:0.00010341951473665169\n",
      "train loss:0.00012831908768778529\n",
      "train loss:4.338587943911975e-05\n",
      "train loss:4.464140660406233e-05\n",
      "train loss:4.633127709405096e-05\n",
      "train loss:2.0761861009954374e-05\n",
      "train loss:5.508842382758982e-05\n",
      "train loss:9.647445498622925e-05\n",
      "train loss:9.115154826150975e-05\n",
      "train loss:0.00018099677859231763\n",
      "train loss:0.00017030374157133622\n",
      "train loss:6.632374601704302e-05\n",
      "train loss:1.543304753540653e-05\n",
      "train loss:3.7516850759221824e-05\n",
      "train loss:9.736164067275878e-06\n",
      "train loss:2.661933931980562e-05\n",
      "train loss:0.00023864506219737732\n",
      "train loss:0.0001765588495063669\n",
      "train loss:2.541716377047849e-05\n",
      "train loss:0.0001022194181589803\n",
      "train loss:0.00010394397187123727\n",
      "train loss:2.144732655071076e-05\n",
      "train loss:0.00027661759538863374\n",
      "train loss:1.4373385169633843e-05\n",
      "train loss:0.00015823102935204737\n",
      "train loss:3.65550823937373e-05\n",
      "train loss:1.7658182558922273e-05\n",
      "train loss:4.5674367078762335e-05\n",
      "train loss:0.0001285148242089591\n",
      "train loss:7.281170327931942e-05\n",
      "train loss:0.0001339957598142048\n",
      "train loss:3.0253821464774126e-05\n",
      "train loss:2.094715546642421e-05\n",
      "train loss:0.0001077625919102163\n",
      "train loss:0.00040174925976402585\n",
      "train loss:8.888635158239304e-05\n",
      "train loss:3.827002827841459e-05\n",
      "train loss:3.710905619680385e-05\n",
      "=== epoch:4, train acc:1.0, test acc:0.964 ===\n",
      "train loss:2.7928762023680858e-05\n",
      "train loss:0.0001070046395626271\n",
      "train loss:3.09716905508121e-05\n",
      "train loss:2.6999169511829927e-05\n",
      "train loss:0.00011529036422590092\n",
      "train loss:3.183418869882467e-05\n",
      "train loss:0.00031250697624823703\n",
      "train loss:0.00018463965027541875\n",
      "train loss:4.414916075208052e-05\n",
      "train loss:3.5985572020127996e-05\n",
      "train loss:3.987048152191567e-05\n",
      "train loss:3.158434605635138e-05\n",
      "train loss:4.2308353844005876e-05\n",
      "train loss:5.6607529009358124e-05\n",
      "train loss:3.6060131002392043e-05\n",
      "train loss:5.274776891114823e-05\n",
      "train loss:0.00016086025288549935\n",
      "train loss:6.629981483918214e-05\n",
      "train loss:3.6839410988646243e-05\n",
      "train loss:0.0003067416065464341\n",
      "train loss:4.69079931844975e-05\n",
      "train loss:0.00011000082162278763\n",
      "train loss:0.0001028601423975298\n",
      "train loss:1.6009162072633003e-05\n",
      "train loss:7.035190587756379e-05\n",
      "train loss:0.00014074980363924653\n",
      "train loss:4.346824119314588e-05\n",
      "train loss:0.00015492974891566648\n",
      "train loss:5.1289198007467075e-05\n",
      "train loss:3.958745103526312e-05\n",
      "train loss:7.84084757574196e-05\n",
      "train loss:9.491740480722227e-05\n",
      "train loss:2.3664747153887573e-05\n",
      "train loss:2.476383782977321e-05\n",
      "train loss:3.935872638143579e-06\n",
      "train loss:8.954532769893176e-05\n",
      "train loss:2.0383366909222204e-05\n",
      "train loss:8.57692628198249e-05\n",
      "train loss:2.5122037353351848e-05\n",
      "train loss:3.2766671785616526e-05\n",
      "train loss:3.2080640753648075e-05\n",
      "train loss:8.812336814586279e-05\n",
      "train loss:3.9983261728120276e-05\n",
      "train loss:6.0201479243254166e-05\n",
      "train loss:7.438462571215998e-05\n",
      "train loss:4.599294375433761e-05\n",
      "train loss:4.142265540279829e-05\n",
      "train loss:4.329587540028287e-05\n",
      "train loss:2.5626525821611464e-05\n",
      "train loss:3.0029675482382075e-05\n",
      "=== epoch:5, train acc:1.0, test acc:0.965 ===\n",
      "train loss:2.6166688761960826e-05\n",
      "train loss:9.275749317251612e-05\n",
      "train loss:5.851177181509243e-05\n",
      "train loss:8.041447675619025e-05\n",
      "train loss:1.667666291188645e-05\n",
      "train loss:7.221493334214584e-05\n",
      "train loss:0.00014777843384847336\n",
      "train loss:8.498210808049889e-06\n",
      "train loss:6.731411331082032e-05\n",
      "train loss:5.7341053279048205e-05\n",
      "train loss:1.461796880742742e-05\n",
      "train loss:2.423823513420055e-05\n",
      "train loss:5.488457831529069e-06\n",
      "train loss:2.2109889891739847e-06\n",
      "train loss:1.2986984378434786e-05\n",
      "train loss:2.7770571840598992e-05\n",
      "train loss:2.5877660312476118e-05\n",
      "train loss:5.9904540174514156e-05\n",
      "train loss:2.0696731992188447e-05\n",
      "train loss:0.00017022429207992748\n",
      "train loss:0.000100406998636872\n",
      "train loss:4.053506781121651e-05\n",
      "train loss:1.7624106572118625e-05\n",
      "train loss:3.977459878876422e-05\n",
      "train loss:0.00012649075617301994\n",
      "train loss:1.878925736070954e-05\n",
      "train loss:6.104350104756663e-05\n",
      "train loss:1.2534882184983337e-05\n",
      "train loss:8.175595019568726e-05\n",
      "train loss:6.234289053780753e-05\n",
      "train loss:7.3884483872435556e-06\n",
      "train loss:2.8426813334488187e-05\n",
      "train loss:0.00011658200078049984\n",
      "train loss:3.6955636820471716e-05\n",
      "train loss:7.452534170051334e-05\n",
      "train loss:1.983156054096144e-05\n",
      "train loss:4.355081962355197e-05\n",
      "train loss:1.5263223557071875e-05\n",
      "train loss:3.1569272530018364e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:6.179694816992337e-05\n",
      "train loss:4.811895950801557e-05\n",
      "train loss:5.64214939775329e-05\n",
      "train loss:1.834633404032354e-05\n",
      "train loss:1.1424885860206837e-05\n",
      "train loss:4.862532936354827e-05\n",
      "train loss:4.3738596604879e-05\n",
      "train loss:3.052276731144662e-05\n",
      "train loss:5.1491185538358635e-05\n",
      "train loss:9.603575718553364e-05\n",
      "train loss:6.578751834258531e-06\n",
      "=== epoch:6, train acc:1.0, test acc:0.965 ===\n",
      "train loss:0.00013790204057552313\n",
      "train loss:5.819126324045836e-05\n",
      "train loss:5.845749220053611e-05\n",
      "train loss:5.0952857349689116e-05\n",
      "train loss:1.4846883341374004e-05\n",
      "train loss:4.6643647426126044e-05\n",
      "train loss:5.8599152620314985e-05\n",
      "train loss:1.4629906634386347e-06\n",
      "train loss:3.7706541043801545e-05\n",
      "train loss:1.4897695182961007e-05\n",
      "train loss:5.738120469389363e-06\n",
      "train loss:1.7160586310640712e-05\n",
      "train loss:7.458810682381578e-06\n",
      "train loss:2.3229254522846573e-05\n",
      "train loss:6.259744457512535e-05\n",
      "train loss:5.213015477132496e-05\n",
      "train loss:7.88460854327345e-05\n",
      "train loss:1.0704528164740014e-05\n",
      "train loss:6.881762706454682e-06\n",
      "train loss:2.3409020630661132e-05\n",
      "train loss:1.7435923095573445e-05\n",
      "train loss:8.924254961258743e-05\n",
      "train loss:4.424311504232108e-05\n",
      "train loss:4.553234065685278e-05\n",
      "train loss:2.7101543197053374e-05\n",
      "train loss:0.00010012009708741176\n",
      "train loss:7.426398665926303e-05\n",
      "train loss:3.2913170120838404e-05\n",
      "train loss:1.518056506112069e-05\n",
      "train loss:1.2538477349004792e-05\n",
      "train loss:2.8294947905058337e-05\n",
      "train loss:3.0505944430425876e-05\n",
      "train loss:2.7494557094936254e-05\n",
      "train loss:3.624219007918742e-05\n",
      "train loss:2.567134783157118e-05\n",
      "train loss:1.1460730532531439e-05\n",
      "train loss:1.843815560520268e-05\n",
      "train loss:1.642860072602176e-05\n",
      "train loss:5.244938266974734e-05\n",
      "train loss:7.143860094457828e-06\n",
      "train loss:3.187636061242747e-05\n",
      "train loss:1.470309845044874e-05\n",
      "train loss:7.894944488028961e-06\n",
      "train loss:1.8084115968567497e-05\n",
      "train loss:3.834585735620847e-05\n",
      "train loss:2.587440721682556e-06\n",
      "train loss:8.79242159231798e-06\n",
      "train loss:5.964983370353166e-05\n",
      "train loss:3.826721194999827e-06\n",
      "train loss:4.679259582398238e-05\n",
      "=== epoch:7, train acc:1.0, test acc:0.966 ===\n",
      "train loss:2.8200171086792395e-05\n",
      "train loss:1.7765343741028883e-05\n",
      "train loss:2.3304711233629303e-05\n",
      "train loss:1.3237557040493561e-05\n",
      "train loss:2.495396177406334e-05\n",
      "train loss:2.7149762454915668e-05\n",
      "train loss:4.772630920473794e-05\n",
      "train loss:3.858507486396196e-05\n",
      "train loss:5.879067169723252e-06\n",
      "train loss:4.626551403256091e-06\n",
      "train loss:1.2426426026565013e-05\n",
      "train loss:1.7475470720417737e-05\n",
      "train loss:2.675604279905887e-05\n",
      "train loss:5.325834278100844e-06\n",
      "train loss:1.9090340972515988e-05\n",
      "train loss:4.1692499784533115e-05\n",
      "train loss:8.691190034196392e-06\n",
      "train loss:1.579938082632331e-05\n",
      "train loss:5.250755633636644e-06\n",
      "train loss:1.0447899254822728e-05\n",
      "train loss:1.1836628781075975e-05\n",
      "train loss:2.6407731566301034e-05\n",
      "train loss:2.5780211749806295e-05\n",
      "train loss:0.00019335263865512956\n",
      "train loss:3.392364912723299e-05\n",
      "train loss:2.1821131535654696e-05\n",
      "train loss:2.199105175403198e-05\n",
      "train loss:6.674637099387e-06\n",
      "train loss:1.920718399793705e-05\n",
      "train loss:9.180128486887185e-06\n",
      "train loss:1.9557584992520173e-05\n",
      "train loss:4.2165977735489746e-05\n",
      "train loss:7.605140908863553e-05\n",
      "train loss:2.2319012401682716e-06\n",
      "train loss:6.771353685709417e-05\n",
      "train loss:7.07336246566108e-05\n",
      "train loss:1.715663551059129e-05\n",
      "train loss:5.449052090272619e-05\n",
      "train loss:1.0830383487940948e-05\n",
      "train loss:1.3198991058640662e-05\n",
      "train loss:3.891305396763355e-05\n",
      "train loss:7.146630559707042e-06\n",
      "train loss:2.5117614995089993e-05\n",
      "train loss:6.538785720810916e-05\n",
      "train loss:3.776306679219557e-05\n",
      "train loss:0.00010759716103549372\n",
      "train loss:0.00011371366390688295\n",
      "train loss:8.314676801498216e-05\n",
      "train loss:5.272408831964128e-05\n",
      "train loss:2.1871017663667435e-05\n",
      "=== epoch:8, train acc:1.0, test acc:0.966 ===\n",
      "train loss:2.1375873410981676e-05\n",
      "train loss:1.466577599871178e-05\n",
      "train loss:4.817927201246285e-05\n",
      "train loss:2.323713428281396e-06\n",
      "train loss:3.3500275026183645e-05\n",
      "train loss:9.44917772144413e-05\n",
      "train loss:4.755562885237521e-05\n",
      "train loss:5.579404215779153e-05\n",
      "train loss:3.5351254279966306e-05\n",
      "train loss:1.8291958673453266e-05\n",
      "train loss:2.2564640578880355e-05\n",
      "train loss:2.9012771453049065e-05\n",
      "train loss:2.9493761801729104e-05\n",
      "train loss:9.300786589608463e-06\n",
      "train loss:5.216828730227972e-06\n",
      "train loss:2.3369953257018402e-05\n",
      "train loss:1.1611061179651148e-05\n",
      "train loss:3.143346238061633e-05\n",
      "train loss:1.744956881951801e-05\n",
      "train loss:5.0829318812339495e-05\n",
      "train loss:4.364387232815265e-06\n",
      "train loss:3.6148636275793975e-05\n",
      "train loss:2.3846530925345034e-05\n",
      "train loss:1.998899021378597e-05\n",
      "train loss:2.437553349210161e-05\n",
      "train loss:4.740020149653098e-05\n",
      "train loss:1.9227101541991088e-05\n",
      "train loss:1.9922413524461852e-05\n",
      "train loss:1.7614166339057428e-05\n",
      "train loss:1.2861756697521877e-05\n",
      "train loss:1.2718173453766948e-05\n",
      "train loss:1.3821258878374546e-05\n",
      "train loss:1.3430702634808448e-05\n",
      "train loss:2.3281521630501048e-05\n",
      "train loss:9.18789725477932e-06\n",
      "train loss:2.8155349530435127e-05\n",
      "train loss:3.6920618919621173e-06\n",
      "train loss:5.06485645709225e-06\n",
      "train loss:4.456787023008135e-05\n",
      "train loss:4.733733136259e-05\n",
      "train loss:2.109910904671431e-05\n",
      "train loss:1.4646336332595265e-05\n",
      "train loss:8.389598157450179e-06\n",
      "train loss:2.7472843408442343e-05\n",
      "train loss:1.3265502419361761e-05\n",
      "train loss:5.849461381818723e-06\n",
      "train loss:3.6807890898563494e-05\n",
      "train loss:9.087504828067907e-06\n",
      "train loss:1.2565677884695482e-05\n",
      "train loss:7.360021588472248e-06\n",
      "=== epoch:9, train acc:1.0, test acc:0.966 ===\n",
      "train loss:5.838099212236224e-05\n",
      "train loss:1.4476353152515616e-05\n",
      "train loss:2.4388597179240195e-05\n",
      "train loss:2.904150564974207e-05\n",
      "train loss:1.1737460414359092e-05\n",
      "train loss:1.9187616216269862e-05\n",
      "train loss:1.1449636377171975e-05\n",
      "train loss:4.592899494113284e-05\n",
      "train loss:2.8470832530841165e-05\n",
      "train loss:2.4421741649742005e-05\n",
      "train loss:9.80681057223084e-06\n",
      "train loss:2.0547001624472843e-05\n",
      "train loss:8.931377217390075e-06\n",
      "train loss:1.6957748377630615e-05\n",
      "train loss:2.2556899625733543e-05\n",
      "train loss:7.910727715872127e-06\n",
      "train loss:9.336855266613789e-06\n",
      "train loss:4.278716987265536e-06\n",
      "train loss:1.681498248095021e-05\n",
      "train loss:3.783406161029786e-05\n",
      "train loss:4.072424882239716e-06\n",
      "train loss:4.190978916019498e-06\n",
      "train loss:1.8634998740447683e-05\n",
      "train loss:1.022273108567504e-05\n",
      "train loss:2.896101954417776e-05\n",
      "train loss:3.822714672157819e-06\n",
      "train loss:1.5520985574974376e-05\n",
      "train loss:1.2359759519203842e-05\n",
      "train loss:3.114441046181937e-05\n",
      "train loss:1.5838215518070112e-05\n",
      "train loss:1.4683056124233046e-05\n",
      "train loss:1.9702000610495218e-05\n",
      "train loss:1.4717209309042891e-05\n",
      "train loss:5.696097092293662e-06\n",
      "train loss:1.034037473345228e-05\n",
      "train loss:3.198849111338928e-05\n",
      "train loss:1.2501277741165696e-05\n",
      "train loss:1.475822800928892e-05\n",
      "train loss:1.311813421120578e-05\n",
      "train loss:7.060266453321012e-06\n",
      "train loss:6.931636083297535e-06\n",
      "train loss:3.3561030933537246e-05\n",
      "train loss:1.8710660931480674e-06\n",
      "train loss:1.9927611452835705e-05\n",
      "train loss:2.2316061339322718e-05\n",
      "train loss:8.250777874437747e-06\n",
      "train loss:2.3107078597882106e-05\n",
      "train loss:2.4527174964169712e-06\n",
      "train loss:2.5506188924957763e-05\n",
      "train loss:9.084752202163322e-06\n",
      "=== epoch:10, train acc:1.0, test acc:0.967 ===\n",
      "train loss:1.112425371433066e-05\n",
      "train loss:1.285967556344802e-05\n",
      "train loss:9.143735628295434e-05\n",
      "train loss:3.8403340333925136e-05\n",
      "train loss:1.2970914024353166e-05\n",
      "train loss:4.9367709075559945e-06\n",
      "train loss:1.2119878874640137e-05\n",
      "train loss:2.873555001674732e-05\n",
      "train loss:6.050289287467018e-06\n",
      "train loss:2.8784770574806804e-05\n",
      "train loss:2.2345629256730954e-05\n",
      "train loss:1.6468884229128857e-05\n",
      "train loss:1.3046233593073468e-05\n",
      "train loss:4.4465042899852665e-05\n",
      "train loss:2.007038575459055e-05\n",
      "train loss:6.343257782347842e-06\n",
      "train loss:6.679538518273681e-06\n",
      "train loss:1.1576169692169312e-05\n",
      "train loss:4.369061073792207e-06\n",
      "train loss:1.3759020687362778e-05\n",
      "train loss:1.3090241287762372e-05\n",
      "train loss:1.0031388477914987e-05\n",
      "train loss:2.6491501480868175e-05\n",
      "train loss:5.943636852657033e-06\n",
      "train loss:1.5579922791133238e-05\n",
      "train loss:1.3038876685668466e-05\n",
      "train loss:2.2704558960977315e-05\n",
      "train loss:4.4436157127930065e-05\n",
      "train loss:1.3548543561567531e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:4.086347530019583e-05\n",
      "train loss:1.0146746471779847e-05\n",
      "train loss:6.570633524624986e-06\n",
      "train loss:4.724261554904623e-05\n",
      "train loss:8.329537054574014e-06\n",
      "train loss:1.9993965921895823e-05\n",
      "train loss:2.5413274667191378e-06\n",
      "train loss:1.2861709748961147e-05\n",
      "train loss:1.2850507211871064e-05\n",
      "train loss:1.0104288665110387e-05\n",
      "train loss:1.3121136716658099e-05\n",
      "train loss:2.5786032075512466e-05\n",
      "train loss:1.3039418931078985e-05\n",
      "train loss:1.4014218726751798e-05\n",
      "train loss:7.865471845175338e-06\n",
      "train loss:1.0013741447660178e-05\n",
      "train loss:9.633844067024797e-06\n",
      "train loss:8.12941033573099e-06\n",
      "train loss:1.532650010546989e-05\n",
      "train loss:2.0955140511496456e-05\n",
      "train loss:1.1401109496974035e-05\n",
      "=== epoch:11, train acc:1.0, test acc:0.966 ===\n",
      "train loss:1.1079209312012123e-05\n",
      "train loss:2.0372007552437334e-05\n",
      "train loss:1.6027378855283152e-06\n",
      "train loss:3.188672808038935e-05\n",
      "train loss:2.5705039176088245e-05\n",
      "train loss:7.007599536393944e-06\n",
      "train loss:1.5770529417174264e-05\n",
      "train loss:6.305575233270218e-05\n",
      "train loss:2.2675529827905286e-05\n",
      "train loss:1.2438440343334236e-05\n",
      "train loss:3.7652677661533094e-05\n",
      "train loss:8.515823006064605e-06\n",
      "train loss:4.502581766915628e-06\n",
      "train loss:1.2869779645706139e-05\n",
      "train loss:1.0995833537142126e-05\n",
      "train loss:7.293399784002719e-06\n",
      "train loss:1.718282846615303e-05\n",
      "train loss:8.004825052546338e-06\n",
      "train loss:5.155620279757492e-06\n",
      "train loss:1.1512391393288736e-05\n",
      "train loss:1.1132451258207692e-05\n",
      "train loss:1.2180078636505485e-05\n",
      "train loss:1.4990555033655326e-05\n",
      "train loss:1.6400609344642637e-05\n",
      "train loss:2.38082699732403e-06\n",
      "train loss:1.7010859592134785e-05\n",
      "train loss:4.887570629143551e-07\n",
      "train loss:1.2446414097574594e-05\n",
      "train loss:1.3606526520747718e-05\n",
      "train loss:1.764500063042508e-05\n",
      "train loss:1.4212318080007158e-05\n",
      "train loss:2.571683432553948e-05\n",
      "train loss:6.665081635439847e-06\n",
      "train loss:3.089036005927952e-05\n",
      "train loss:9.869485133712043e-06\n",
      "train loss:4.432483286791869e-06\n",
      "train loss:2.858094372428268e-05\n",
      "train loss:2.3701052639386253e-06\n",
      "train loss:2.7012564491065275e-05\n",
      "train loss:2.949394048082458e-05\n",
      "train loss:4.172107747537355e-06\n",
      "train loss:1.051774122387573e-05\n",
      "train loss:6.3959533058623005e-06\n",
      "train loss:1.4765403895603935e-05\n",
      "train loss:9.122062110782629e-06\n",
      "train loss:4.644496766304586e-06\n",
      "train loss:1.2198315984075764e-05\n",
      "train loss:5.855855637415816e-06\n",
      "train loss:1.4465886853425066e-05\n",
      "train loss:1.9664375574364445e-05\n",
      "=== epoch:12, train acc:1.0, test acc:0.966 ===\n",
      "train loss:3.286424180298141e-05\n",
      "train loss:1.2630676619582673e-05\n",
      "train loss:8.937969843070888e-06\n",
      "train loss:6.762882932981165e-06\n",
      "train loss:1.4737381149424293e-05\n",
      "train loss:1.7703884456667905e-05\n",
      "train loss:7.161322229514747e-06\n",
      "train loss:1.9600296962230643e-05\n",
      "train loss:4.002216482292579e-05\n",
      "train loss:1.5409823107578513e-05\n",
      "train loss:3.410208710588832e-06\n",
      "train loss:1.335451165628895e-05\n",
      "train loss:1.0593282325446948e-05\n",
      "train loss:3.922692733166271e-06\n",
      "train loss:2.1692618561100068e-05\n",
      "train loss:2.198807508119215e-05\n",
      "train loss:7.724459108029516e-06\n",
      "train loss:7.920239807157417e-06\n",
      "train loss:1.4118506374392225e-05\n",
      "train loss:2.223134657358043e-05\n",
      "train loss:2.833970429362177e-05\n",
      "train loss:3.002775810407288e-05\n",
      "train loss:3.66053148286126e-05\n",
      "train loss:2.7353264539652977e-05\n",
      "train loss:9.538865173432202e-06\n",
      "train loss:4.1601921401190745e-06\n",
      "train loss:2.0790144418984564e-06\n",
      "train loss:2.069031315312575e-05\n",
      "train loss:2.2235854629112867e-05\n",
      "train loss:1.3810848504278874e-05\n",
      "train loss:4.559060246871352e-06\n",
      "train loss:5.701338195671036e-06\n",
      "train loss:8.279464854366822e-06\n",
      "train loss:2.070255519447771e-05\n",
      "train loss:1.3761454982058967e-05\n",
      "train loss:2.3174964854869082e-05\n",
      "train loss:1.0841814814432157e-06\n",
      "train loss:4.9137582769625514e-06\n",
      "train loss:8.734219224354556e-06\n",
      "train loss:5.442520540329775e-06\n",
      "train loss:1.1642889163525919e-05\n",
      "train loss:2.2397214154649983e-05\n",
      "train loss:1.798156196881087e-05\n",
      "train loss:1.1516983641103215e-05\n",
      "train loss:2.7162350665408927e-05\n",
      "train loss:5.008730740419176e-06\n",
      "train loss:1.0928580830166012e-05\n",
      "train loss:1.9524572680268012e-05\n",
      "train loss:6.156667219615121e-06\n",
      "train loss:1.1350448644215387e-05\n",
      "=== epoch:13, train acc:1.0, test acc:0.966 ===\n",
      "train loss:2.1671904566886495e-06\n",
      "train loss:1.0683096082571069e-05\n",
      "train loss:6.845109938662497e-06\n",
      "train loss:9.183677653226017e-06\n",
      "train loss:1.153431627069717e-05\n",
      "train loss:1.1240125723539556e-05\n",
      "train loss:9.279441626732456e-06\n",
      "train loss:2.8267764236868443e-05\n",
      "train loss:9.901880141588074e-06\n",
      "train loss:1.0870720918473722e-05\n",
      "train loss:2.2064179657761376e-06\n",
      "train loss:1.4498495765059279e-05\n",
      "train loss:3.686355810137696e-05\n",
      "train loss:1.652585594219352e-05\n",
      "train loss:3.123968161689303e-05\n",
      "train loss:8.380813248870252e-06\n",
      "train loss:1.0550121262804535e-05\n",
      "train loss:1.515773790423786e-05\n",
      "train loss:9.981237448892129e-06\n",
      "train loss:5.2073730364646885e-06\n",
      "train loss:1.1600003882806908e-05\n",
      "train loss:2.180388460368825e-05\n",
      "train loss:9.39411045015528e-06\n",
      "train loss:2.7418462428826094e-05\n",
      "train loss:1.3809847344424775e-05\n",
      "train loss:5.721612547076764e-06\n",
      "train loss:8.227799253884141e-06\n",
      "train loss:4.945735472049394e-06\n",
      "train loss:8.474956685681355e-06\n",
      "train loss:7.937465010857118e-06\n",
      "train loss:4.087208947224351e-06\n",
      "train loss:2.1746269250699476e-06\n",
      "train loss:5.413134456514098e-06\n",
      "train loss:6.05369720023978e-06\n",
      "train loss:1.3184807389473768e-05\n",
      "train loss:1.982831524740433e-05\n",
      "train loss:9.46359254445253e-06\n",
      "train loss:7.034721154965785e-06\n",
      "train loss:6.8751450450920406e-06\n",
      "train loss:1.3786747008269068e-05\n",
      "train loss:5.959741895448251e-06\n",
      "train loss:1.7660772576097393e-05\n",
      "train loss:5.962974407322885e-06\n",
      "train loss:3.216385954196249e-06\n",
      "train loss:7.538194856700277e-06\n",
      "train loss:1.4055522971055672e-05\n",
      "train loss:8.27828896940458e-06\n",
      "train loss:1.6348407955362146e-05\n",
      "train loss:8.880453263709253e-06\n",
      "train loss:2.0194315902639232e-05\n",
      "=== epoch:14, train acc:1.0, test acc:0.967 ===\n",
      "train loss:2.097439639567923e-05\n",
      "train loss:4.019428409005443e-06\n",
      "train loss:3.051213826065569e-06\n",
      "train loss:1.0519144723865413e-05\n",
      "train loss:4.023708581965438e-06\n",
      "train loss:3.419363414590734e-05\n",
      "train loss:1.6346538184041124e-05\n",
      "train loss:1.1925232505255068e-05\n",
      "train loss:2.6546518443753016e-05\n",
      "train loss:2.3550666697772178e-06\n",
      "train loss:1.186904736723451e-05\n",
      "train loss:1.5572052904607716e-05\n",
      "train loss:6.598302101364457e-06\n",
      "train loss:3.3440622246922814e-06\n",
      "train loss:8.182028816710171e-06\n",
      "train loss:3.29641555231188e-06\n",
      "train loss:6.7309579218781425e-06\n",
      "train loss:1.8594235049587086e-06\n",
      "train loss:1.0263844521132198e-05\n",
      "train loss:3.7681337450649656e-06\n",
      "train loss:1.433329376075162e-05\n",
      "train loss:1.9163211600477987e-05\n",
      "train loss:5.300128005977925e-06\n",
      "train loss:1.0824182292157006e-05\n",
      "train loss:5.353928084836123e-06\n",
      "train loss:7.936324596374822e-06\n",
      "train loss:4.5582661875133175e-06\n",
      "train loss:1.641083890542207e-05\n",
      "train loss:2.8212823013687966e-05\n",
      "train loss:1.0435118751204199e-05\n",
      "train loss:5.054360793532145e-06\n",
      "train loss:1.585003775136573e-05\n",
      "train loss:6.376144767683063e-06\n",
      "train loss:1.4769457152132698e-05\n",
      "train loss:1.87570292899983e-05\n",
      "train loss:6.066234981304111e-06\n",
      "train loss:1.1681631615951739e-05\n",
      "train loss:2.2795386458410094e-05\n",
      "train loss:1.3742697976846921e-05\n",
      "train loss:4.875035773481812e-06\n",
      "train loss:7.226300378928895e-06\n",
      "train loss:6.803894019982428e-06\n",
      "train loss:7.1056888198597586e-06\n",
      "train loss:9.322653920349769e-06\n",
      "train loss:7.273597283802549e-06\n",
      "train loss:4.408720170527767e-06\n",
      "train loss:1.4650499119331125e-05\n",
      "train loss:4.328002542364711e-06\n",
      "train loss:5.8504552794352295e-06\n",
      "train loss:1.8356014851716677e-05\n",
      "=== epoch:15, train acc:1.0, test acc:0.966 ===\n",
      "train loss:1.576928322175119e-05\n",
      "train loss:6.216883008834997e-06\n",
      "train loss:6.181605508424025e-06\n",
      "train loss:5.211318370094274e-06\n",
      "train loss:2.4429597785640473e-05\n",
      "train loss:4.985613709545196e-06\n",
      "train loss:6.468554328954673e-06\n",
      "train loss:1.0333821131351005e-05\n",
      "train loss:1.8226071251152675e-06\n",
      "train loss:1.3159842295285505e-05\n",
      "train loss:9.582152736563134e-06\n",
      "train loss:5.529373402478932e-06\n",
      "train loss:5.568998697951542e-06\n",
      "train loss:8.54545229340895e-06\n",
      "train loss:1.1386004991971138e-05\n",
      "train loss:7.909767918068832e-06\n",
      "train loss:1.2852006928078935e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:3.982059776897931e-06\n",
      "train loss:4.7773769743667e-06\n",
      "train loss:1.6110500652301436e-05\n",
      "train loss:1.1002600684976017e-05\n",
      "train loss:1.0390701562951027e-05\n",
      "train loss:8.394504025701995e-06\n",
      "train loss:1.141973456707808e-05\n",
      "train loss:1.8527063328581834e-05\n",
      "train loss:2.4194248572630018e-05\n",
      "train loss:2.5423059586684187e-06\n",
      "train loss:4.909043667206152e-06\n",
      "train loss:3.3500168850159834e-06\n",
      "train loss:4.981311933525165e-06\n",
      "train loss:4.879823286368635e-06\n",
      "train loss:1.621641952966914e-05\n",
      "train loss:2.0094763914064714e-05\n",
      "train loss:1.3985162249524216e-05\n",
      "train loss:8.748060331390867e-06\n",
      "train loss:1.6725089760151443e-05\n",
      "train loss:4.211775466925632e-06\n",
      "train loss:7.0194998606615025e-06\n",
      "train loss:5.233682890438761e-06\n",
      "train loss:6.219147440118071e-06\n",
      "train loss:1.751661880990069e-06\n",
      "train loss:4.743348219038021e-06\n",
      "train loss:5.148367149938354e-06\n",
      "train loss:1.3673465425312082e-05\n",
      "train loss:8.047664118598791e-06\n",
      "train loss:5.523731298288445e-06\n",
      "train loss:4.4763082468206185e-06\n",
      "train loss:5.388731466296315e-06\n",
      "train loss:6.263074484906814e-06\n",
      "train loss:3.140334063319465e-06\n",
      "=== epoch:16, train acc:1.0, test acc:0.966 ===\n",
      "train loss:4.2448132018023066e-06\n",
      "train loss:7.054720752207242e-06\n",
      "train loss:6.740629532036263e-07\n",
      "train loss:5.8421761249971254e-06\n",
      "train loss:3.482745321941614e-06\n",
      "train loss:1.4281202652479167e-06\n",
      "train loss:9.417471574990691e-06\n",
      "train loss:8.217694495107473e-06\n",
      "train loss:3.5836533178044925e-06\n",
      "train loss:1.8568551287870567e-05\n",
      "train loss:7.74924592687817e-06\n",
      "train loss:5.925223876138821e-06\n",
      "train loss:1.6328058339078296e-05\n",
      "train loss:5.3466743698806005e-06\n",
      "train loss:2.4249842077533647e-06\n",
      "train loss:7.288114485688597e-07\n",
      "train loss:1.2860613130327978e-05\n",
      "train loss:4.396266864564671e-06\n",
      "train loss:2.9364725027956097e-06\n",
      "train loss:1.1308696213052278e-05\n",
      "train loss:5.1405166579862216e-06\n",
      "train loss:5.714008134384653e-06\n",
      "train loss:5.356929123618638e-06\n",
      "train loss:9.168490506142379e-06\n",
      "train loss:3.4791861028971907e-06\n",
      "train loss:7.174614503891732e-06\n",
      "train loss:5.0410176766697615e-06\n",
      "train loss:4.06040877875001e-06\n",
      "train loss:4.580356176912381e-06\n",
      "train loss:1.0534949043360462e-05\n",
      "train loss:1.0570720115697997e-05\n",
      "train loss:3.36677469547286e-06\n",
      "train loss:1.3288582721388546e-05\n",
      "train loss:4.947754564050817e-06\n",
      "train loss:6.446914872718921e-06\n",
      "train loss:2.5915188202212325e-06\n",
      "train loss:5.83964580226199e-06\n",
      "train loss:2.430962139500877e-06\n",
      "train loss:4.152613268670651e-06\n",
      "train loss:9.704152644753754e-06\n",
      "train loss:2.316995894443473e-06\n",
      "train loss:2.5300238528815746e-06\n",
      "train loss:5.097089083776541e-06\n",
      "train loss:2.945781241724242e-06\n",
      "train loss:7.1136990612990145e-06\n",
      "train loss:5.333747659838955e-06\n",
      "train loss:5.80058639573158e-06\n",
      "train loss:9.095331187464172e-06\n",
      "train loss:1.339769437935057e-05\n",
      "train loss:3.250794299253155e-06\n",
      "=== epoch:17, train acc:1.0, test acc:0.966 ===\n",
      "train loss:6.240575447540997e-06\n",
      "train loss:3.962084215049526e-06\n",
      "train loss:1.0225042741753099e-05\n",
      "train loss:2.8854956863316104e-06\n",
      "train loss:7.749862591577187e-06\n",
      "train loss:2.1347705126127406e-05\n",
      "train loss:1.0075600428108598e-06\n",
      "train loss:2.5060322360638106e-05\n",
      "train loss:9.608405561441887e-06\n",
      "train loss:1.5323099545758425e-06\n",
      "train loss:3.2427436733013076e-06\n",
      "train loss:8.201968764138921e-06\n",
      "train loss:7.06845550652769e-06\n",
      "train loss:2.005713695946414e-06\n",
      "train loss:1.0279662987946402e-05\n",
      "train loss:4.7394398654209855e-06\n",
      "train loss:8.608551343073702e-06\n",
      "train loss:1.5924455238749893e-06\n",
      "train loss:5.643435898426573e-06\n",
      "train loss:6.496480363243994e-07\n",
      "train loss:4.2877723124182795e-06\n",
      "train loss:1.0719156155434813e-05\n",
      "train loss:7.078550754438928e-06\n",
      "train loss:1.187138911494788e-05\n",
      "train loss:4.336466716782334e-06\n",
      "train loss:1.2018676581870479e-05\n",
      "train loss:1.0420676050034185e-05\n",
      "train loss:4.722535184485419e-06\n",
      "train loss:5.631854852064505e-06\n",
      "train loss:4.335415476066807e-06\n",
      "train loss:7.334662975664805e-07\n",
      "train loss:1.1623212211658494e-05\n",
      "train loss:6.328395179298532e-06\n",
      "train loss:3.548782394293596e-06\n",
      "train loss:6.766259644949418e-06\n",
      "train loss:1.2542968664891344e-05\n",
      "train loss:1.7516574208145696e-06\n",
      "train loss:4.898014965525323e-06\n",
      "train loss:3.901710356785352e-06\n",
      "train loss:2.581138635183421e-06\n",
      "train loss:6.010824154246732e-06\n",
      "train loss:7.880380481778798e-06\n",
      "train loss:5.3713613998643795e-06\n",
      "train loss:7.791543569955442e-06\n",
      "train loss:6.183073334765544e-06\n",
      "train loss:2.405199917000272e-06\n",
      "train loss:5.567803872234834e-06\n",
      "train loss:6.122370773493408e-06\n",
      "train loss:3.939915421803823e-06\n",
      "train loss:1.9868027327323276e-05\n",
      "=== epoch:18, train acc:1.0, test acc:0.967 ===\n",
      "train loss:1.8877129253889702e-06\n",
      "train loss:2.1471168719699002e-06\n",
      "train loss:2.1786455385043904e-05\n",
      "train loss:6.442074598073288e-06\n",
      "train loss:4.876789881999349e-06\n",
      "train loss:6.199193230652978e-06\n",
      "train loss:3.5635804290893956e-06\n",
      "train loss:1.649857469007798e-06\n",
      "train loss:2.8827572467826397e-06\n",
      "train loss:9.952286755836724e-06\n",
      "train loss:8.784670639270917e-06\n",
      "train loss:3.3964416542423254e-06\n",
      "train loss:6.4022283880330296e-06\n",
      "train loss:2.5652649240730478e-06\n",
      "train loss:7.814622749881507e-06\n",
      "train loss:3.53524059307729e-06\n",
      "train loss:6.639035882766515e-06\n",
      "train loss:1.112237351417891e-05\n",
      "train loss:2.486342748772962e-06\n",
      "train loss:5.302621240636193e-06\n",
      "train loss:6.82530535116454e-07\n",
      "train loss:9.277264522863133e-06\n",
      "train loss:5.051174267903718e-06\n",
      "train loss:1.5694140409139745e-05\n",
      "train loss:1.3191841651039939e-05\n",
      "train loss:1.0864812403633908e-05\n",
      "train loss:4.290001233294515e-06\n",
      "train loss:2.1893980185530417e-06\n",
      "train loss:2.5975831952818448e-06\n",
      "train loss:1.037043717516668e-05\n",
      "train loss:5.160355875681474e-06\n",
      "train loss:4.393034237070947e-06\n",
      "train loss:2.2899255882446637e-06\n",
      "train loss:9.681341797297369e-06\n",
      "train loss:1.313410018077174e-06\n",
      "train loss:5.790778371898976e-06\n",
      "train loss:4.28968715645872e-06\n",
      "train loss:9.498101168106e-06\n",
      "train loss:2.887901575349701e-06\n",
      "train loss:2.02157892303539e-06\n",
      "train loss:5.004585235710981e-06\n",
      "train loss:3.508744856817724e-06\n",
      "train loss:6.266410214327646e-06\n",
      "train loss:7.478550099889404e-06\n",
      "train loss:4.70953275646901e-06\n",
      "train loss:3.490273723924222e-06\n",
      "train loss:1.3839012876035115e-06\n",
      "train loss:5.777583122527423e-06\n",
      "train loss:5.400453375189074e-07\n",
      "train loss:4.850075324717769e-06\n",
      "=== epoch:19, train acc:1.0, test acc:0.967 ===\n",
      "train loss:3.2299217771849516e-06\n",
      "train loss:8.854300694078924e-07\n",
      "train loss:2.4158482213203438e-06\n",
      "train loss:8.211850999601104e-06\n",
      "train loss:3.6622730222515055e-06\n",
      "train loss:1.1549475570349149e-05\n",
      "train loss:9.11387124610956e-06\n",
      "train loss:2.2812128663411787e-06\n",
      "train loss:3.5998385526353314e-06\n",
      "train loss:5.1901654960111665e-06\n",
      "train loss:8.684983871095218e-06\n",
      "train loss:1.050216160629041e-05\n",
      "train loss:2.7795465165597715e-06\n",
      "train loss:4.1709463453502e-06\n",
      "train loss:3.226735871576953e-06\n",
      "train loss:3.6445725201700457e-06\n",
      "train loss:1.730439615619605e-06\n",
      "train loss:2.634910969244797e-06\n",
      "train loss:1.336319678719926e-05\n",
      "train loss:1.1590125862141208e-06\n",
      "train loss:1.6257289913171822e-05\n",
      "train loss:2.9836950495500006e-06\n",
      "train loss:6.87467932376855e-07\n",
      "train loss:3.1532376434075393e-06\n",
      "train loss:5.924393288567917e-06\n",
      "train loss:8.92972520144989e-06\n",
      "train loss:1.239031255538491e-05\n",
      "train loss:4.303188024255391e-06\n",
      "train loss:7.634696413136427e-07\n",
      "train loss:4.323201277008565e-06\n",
      "train loss:1.5093768575930468e-05\n",
      "train loss:3.712279662620878e-06\n",
      "train loss:5.50340025657028e-06\n",
      "train loss:5.370201819506746e-06\n",
      "train loss:5.570033075791943e-07\n",
      "train loss:2.5206530612427323e-06\n",
      "train loss:9.236151206718698e-06\n",
      "train loss:4.396825325273151e-06\n",
      "train loss:3.5392603048300184e-07\n",
      "train loss:3.5215274267040375e-06\n",
      "train loss:1.3730802993030093e-05\n",
      "train loss:1.1741489894045616e-05\n",
      "train loss:1.7261210918278746e-06\n",
      "train loss:5.523855024932173e-06\n",
      "train loss:7.538458685681237e-06\n",
      "train loss:1.6564879004432514e-06\n",
      "train loss:5.5512829605215314e-06\n",
      "train loss:1.7264107363756317e-06\n",
      "train loss:5.297455298444252e-06\n",
      "train loss:5.047260838172024e-06\n",
      "=== epoch:20, train acc:1.0, test acc:0.968 ===\n",
      "train loss:2.7396999164394825e-06\n",
      "train loss:2.3810885176046004e-06\n",
      "train loss:1.234005457702755e-05\n",
      "train loss:6.355761275075306e-06\n",
      "train loss:1.2283535647283641e-05\n",
      "train loss:1.2039166074029863e-05\n",
      "train loss:4.719792605842492e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:7.744396009395427e-06\n",
      "train loss:9.832518434487336e-06\n",
      "train loss:4.799923268120939e-06\n",
      "train loss:4.164992811965162e-06\n",
      "train loss:5.82117112927757e-06\n",
      "train loss:3.350284555222888e-06\n",
      "train loss:1.8272353570680694e-06\n",
      "train loss:1.9170227911079173e-06\n",
      "train loss:2.098503830194951e-06\n",
      "train loss:1.5570080482379494e-05\n",
      "train loss:4.442171053602329e-06\n",
      "train loss:5.196792061724088e-07\n",
      "train loss:1.140842447988783e-05\n",
      "train loss:4.454057834827722e-06\n",
      "train loss:3.4976880126866474e-06\n",
      "train loss:3.1966954388458763e-06\n",
      "train loss:6.831916357974091e-06\n",
      "train loss:5.236698444665769e-06\n",
      "train loss:2.4983928704428177e-06\n",
      "train loss:7.938885015373082e-06\n",
      "train loss:5.486789733566624e-07\n",
      "train loss:3.869131958605279e-07\n",
      "train loss:1.2285420077583873e-06\n",
      "train loss:1.1383460085001401e-06\n",
      "train loss:2.7936703371507764e-06\n",
      "train loss:8.027752498564895e-06\n",
      "train loss:1.3719788841299014e-05\n",
      "train loss:1.6761844561938258e-06\n",
      "train loss:3.315984476546445e-06\n",
      "train loss:1.3461308535333128e-05\n",
      "train loss:5.646198712456386e-06\n",
      "train loss:4.904829842676937e-06\n",
      "train loss:5.3107591218483224e-06\n",
      "train loss:2.1071223141965933e-06\n",
      "train loss:6.351668743549453e-06\n",
      "train loss:9.765950682821347e-06\n",
      "train loss:3.7431000627758837e-06\n",
      "train loss:1.2325225498414582e-06\n",
      "train loss:1.891912747859291e-05\n",
      "train loss:4.719790690921652e-06\n",
      "train loss:3.986181628522351e-06\n",
      "train loss:3.4865756946584715e-06\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.967\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "# パラメータの保存\n",
    "network.save_params(opti + \".params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "#plt.yscale(\"log\")\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
